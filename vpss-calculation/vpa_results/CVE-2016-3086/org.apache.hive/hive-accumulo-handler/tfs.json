{
  "2.3.3": [
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: void configure(org.apache.hadoop.mapred.JobConf,org.apache.accumulo.core.client.Instance,org.apache.accumulo.core.client.Connector,org.apache.hadoop.hive.accumulo.AccumuloConnectionParameters,org.apache.hadoop.hive.accumulo.columns.ColumnMapper,java.util.List,java.util.Collection)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat: org.apache.hadoop.security.UserGroupInformation getCurrentUser()>",
    "<org.apache.hadoop.hive.accumulo.Utils: void addDependencyJars(org.apache.hadoop.conf.Configuration,java.lang.Class[])>"
  ],
  "2.3.2": [
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: void configure(org.apache.hadoop.mapred.JobConf,org.apache.accumulo.core.client.Instance,org.apache.accumulo.core.client.Connector,org.apache.hadoop.hive.accumulo.AccumuloConnectionParameters,org.apache.hadoop.hive.accumulo.columns.ColumnMapper,java.util.List,java.util.Collection)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat: org.apache.hadoop.security.UserGroupInformation getCurrentUser()>",
    "<org.apache.hadoop.hive.accumulo.Utils: void addDependencyJars(org.apache.hadoop.conf.Configuration,java.lang.Class[])>"
  ],
  "2.3.5": [
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: void configure(org.apache.hadoop.mapred.JobConf,org.apache.accumulo.core.client.Instance,org.apache.accumulo.core.client.Connector,org.apache.hadoop.hive.accumulo.AccumuloConnectionParameters,org.apache.hadoop.hive.accumulo.columns.ColumnMapper,java.util.List,java.util.Collection)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat: org.apache.hadoop.security.UserGroupInformation getCurrentUser()>",
    "<org.apache.hadoop.hive.accumulo.Utils: void addDependencyJars(org.apache.hadoop.conf.Configuration,java.lang.Class[])>"
  ],
  "2.3.8": [
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: void configure(org.apache.hadoop.mapred.JobConf,org.apache.accumulo.core.client.Instance,org.apache.accumulo.core.client.Connector,org.apache.hadoop.hive.accumulo.AccumuloConnectionParameters,org.apache.hadoop.hive.accumulo.columns.ColumnMapper,java.util.List,java.util.Collection)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat: org.apache.hadoop.security.UserGroupInformation getCurrentUser()>",
    "<org.apache.hadoop.hive.accumulo.Utils: void addDependencyJars(org.apache.hadoop.conf.Configuration,java.lang.Class[])>"
  ],
  "2.3.9": [
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: void configure(org.apache.hadoop.mapred.JobConf,org.apache.accumulo.core.client.Instance,org.apache.accumulo.core.client.Connector,org.apache.hadoop.hive.accumulo.AccumuloConnectionParameters,org.apache.hadoop.hive.accumulo.columns.ColumnMapper,java.util.List,java.util.Collection)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat: org.apache.hadoop.security.UserGroupInformation getCurrentUser()>",
    "<org.apache.hadoop.hive.accumulo.Utils: void addDependencyJars(org.apache.hadoop.conf.Configuration,java.lang.Class[])>"
  ],
  "2.3.4": [
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: void configure(org.apache.hadoop.mapred.JobConf,org.apache.accumulo.core.client.Instance,org.apache.accumulo.core.client.Connector,org.apache.hadoop.hive.accumulo.AccumuloConnectionParameters,org.apache.hadoop.hive.accumulo.columns.ColumnMapper,java.util.List,java.util.Collection)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat: org.apache.hadoop.security.UserGroupInformation getCurrentUser()>",
    "<org.apache.hadoop.hive.accumulo.Utils: void addDependencyJars(org.apache.hadoop.conf.Configuration,java.lang.Class[])>"
  ],
  "2.3.10": [
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: void configure(org.apache.hadoop.mapred.JobConf,org.apache.accumulo.core.client.Instance,org.apache.accumulo.core.client.Connector,org.apache.hadoop.hive.accumulo.AccumuloConnectionParameters,org.apache.hadoop.hive.accumulo.columns.ColumnMapper,java.util.List,java.util.Collection)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat: org.apache.hadoop.security.UserGroupInformation getCurrentUser()>",
    "<org.apache.hadoop.hive.accumulo.Utils: void addDependencyJars(org.apache.hadoop.conf.Configuration,java.lang.Class[])>"
  ],
  "2.3.1": [
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: void configure(org.apache.hadoop.mapred.JobConf,org.apache.accumulo.core.client.Instance,org.apache.accumulo.core.client.Connector,org.apache.hadoop.hive.accumulo.AccumuloConnectionParameters,org.apache.hadoop.hive.accumulo.columns.ColumnMapper,java.util.List,java.util.Collection)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat: org.apache.hadoop.security.UserGroupInformation getCurrentUser()>",
    "<org.apache.hadoop.hive.accumulo.Utils: void addDependencyJars(org.apache.hadoop.conf.Configuration,java.lang.Class[])>"
  ],
  "2.3.7": [
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: void configure(org.apache.hadoop.mapred.JobConf,org.apache.accumulo.core.client.Instance,org.apache.accumulo.core.client.Connector,org.apache.hadoop.hive.accumulo.AccumuloConnectionParameters,org.apache.hadoop.hive.accumulo.columns.ColumnMapper,java.util.List,java.util.Collection)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat: org.apache.hadoop.security.UserGroupInformation getCurrentUser()>",
    "<org.apache.hadoop.hive.accumulo.Utils: void addDependencyJars(org.apache.hadoop.conf.Configuration,java.lang.Class[])>"
  ],
  "2.3.6": [
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: void configure(org.apache.hadoop.mapred.JobConf,org.apache.accumulo.core.client.Instance,org.apache.accumulo.core.client.Connector,org.apache.hadoop.hive.accumulo.AccumuloConnectionParameters,org.apache.hadoop.hive.accumulo.columns.ColumnMapper,java.util.List,java.util.Collection)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat: org.apache.hadoop.security.UserGroupInformation getCurrentUser()>",
    "<org.apache.hadoop.hive.accumulo.Utils: void addDependencyJars(org.apache.hadoop.conf.Configuration,java.lang.Class[])>"
  ],
  "2.3.0": [
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: void configure(org.apache.hadoop.mapred.JobConf,org.apache.accumulo.core.client.Instance,org.apache.accumulo.core.client.Connector,org.apache.hadoop.hive.accumulo.AccumuloConnectionParameters,org.apache.hadoop.hive.accumulo.columns.ColumnMapper,java.util.List,java.util.Collection)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat: org.apache.hadoop.security.UserGroupInformation getCurrentUser()>",
    "<org.apache.hadoop.hive.accumulo.Utils: void addDependencyJars(org.apache.hadoop.conf.Configuration,java.lang.Class[])>"
  ],
  "2.0.1": [
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: void configure(org.apache.hadoop.mapred.JobConf,org.apache.accumulo.core.client.Instance,org.apache.accumulo.core.client.Connector,org.apache.hadoop.hive.accumulo.AccumuloConnectionParameters,org.apache.hadoop.hive.accumulo.columns.ColumnMapper,java.util.List,java.util.Collection)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat: org.apache.hadoop.security.UserGroupInformation getCurrentUser()>",
    "<org.apache.hadoop.hive.accumulo.Utils: void addDependencyJars(org.apache.hadoop.conf.Configuration,java.lang.Class[])>"
  ],
  "2.0.0": [
    "<org.apache.hadoop.hive.accumulo.predicate.AccumuloRangeGenerator: java.lang.Object process(org.apache.hadoop.hive.ql.lib.Node,java.util.Stack,org.apache.hadoop.hive.ql.lib.NodeProcessorCtx,java.lang.Object[])>",
    "<org.apache.hadoop.hive.accumulo.serde.DefaultAccumuloRowIdFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createRowIdObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloRecordReader: boolean next(org.apache.hadoop.io.Text,org.apache.hadoop.hive.accumulo.AccumuloHiveRow)>",
    "<org.apache.hadoop.hive.accumulo.serde.AccumuloSerDe: java.util.ArrayList getColumnObjectInspectors(java.util.List,org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters,java.util.List,org.apache.hadoop.hive.accumulo.serde.AccumuloRowIdFactory)>",
    "<org.apache.hadoop.hive.accumulo.predicate.PushdownTuple: void <init>(org.apache.hadoop.hive.ql.index.IndexSearchCondition,org.apache.hadoop.hive.accumulo.predicate.compare.PrimitiveComparison,org.apache.hadoop.hive.accumulo.predicate.compare.CompareOp)>",
    "<org.apache.hadoop.hive.accumulo.predicate.AccumuloPredicateHandler: org.apache.hadoop.hive.ql.plan.ExprNodeDesc getExpression(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.HiveAccumuloHelper: void mergeTokenIntoJobConf(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.security.token.Token)>",
    "<org.apache.hadoop.hive.accumulo.serde.AccumuloRowSerializer: void writeString(org.apache.hadoop.hive.serde2.ByteStream$Output,java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector)>",
    "<org.apache.hadoop.hive.accumulo.predicate.PrimitiveComparisonFilter: boolean filter(org.apache.hadoop.io.Text,java.util.List,java.util.List)>"
  ],
  "2.1.0": [
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: void configure(org.apache.hadoop.mapred.JobConf,org.apache.accumulo.core.client.Instance,org.apache.accumulo.core.client.Connector,org.apache.hadoop.hive.accumulo.AccumuloConnectionParameters,org.apache.hadoop.hive.accumulo.columns.ColumnMapper,java.util.List,java.util.Collection)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat: org.apache.hadoop.security.UserGroupInformation getCurrentUser()>",
    "<org.apache.hadoop.hive.accumulo.Utils: void addDependencyJars(org.apache.hadoop.conf.Configuration,java.lang.Class[])>"
  ],
  "2.1.1": [
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: void configure(org.apache.hadoop.mapred.JobConf,org.apache.accumulo.core.client.Instance,org.apache.accumulo.core.client.Connector,org.apache.hadoop.hive.accumulo.AccumuloConnectionParameters,org.apache.hadoop.hive.accumulo.columns.ColumnMapper,java.util.List,java.util.Collection)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableOutputFormat: org.apache.hadoop.security.UserGroupInformation getCurrentUser()>",
    "<org.apache.hadoop.hive.accumulo.Utils: void addDependencyJars(org.apache.hadoop.conf.Configuration,java.lang.Class[])>"
  ],
  "1.2.0": [
    "<org.apache.hadoop.hive.accumulo.serde.DefaultAccumuloRowIdFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createRowIdObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloRecordReader: boolean next(org.apache.hadoop.io.Text,org.apache.hadoop.hive.accumulo.AccumuloHiveRow)>",
    "<org.apache.hadoop.hive.accumulo.serde.AccumuloSerDe: java.util.ArrayList getColumnObjectInspectors(java.util.List,org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters,java.util.List,org.apache.hadoop.hive.accumulo.serde.AccumuloRowIdFactory)>",
    "<org.apache.hadoop.hive.accumulo.predicate.AccumuloRangeGenerator: java.lang.Object processExpression(org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc,java.lang.Object[])>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.serde.AccumuloSerDeParameters: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,java.lang.String)>",
    "<org.apache.hadoop.hive.accumulo.serde.AccumuloRowSerializer: void writeString(org.apache.hadoop.hive.serde2.ByteStream$Output,java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector)>",
    "<org.apache.hadoop.hive.accumulo.predicate.PrimitiveComparisonFilter: boolean filter(org.apache.hadoop.io.Text,java.util.List,java.util.List)>"
  ],
  "1.2.1": [
    "<org.apache.hadoop.hive.accumulo.serde.DefaultAccumuloRowIdFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createRowIdObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloRecordReader: boolean next(org.apache.hadoop.io.Text,org.apache.hadoop.hive.accumulo.AccumuloHiveRow)>",
    "<org.apache.hadoop.hive.accumulo.serde.AccumuloSerDe: java.util.ArrayList getColumnObjectInspectors(java.util.List,org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters,java.util.List,org.apache.hadoop.hive.accumulo.serde.AccumuloRowIdFactory)>",
    "<org.apache.hadoop.hive.accumulo.predicate.PushdownTuple: void <init>(org.apache.hadoop.hive.ql.index.IndexSearchCondition,org.apache.hadoop.hive.accumulo.predicate.compare.PrimitiveComparison,org.apache.hadoop.hive.accumulo.predicate.compare.CompareOp)>",
    "<org.apache.hadoop.hive.accumulo.predicate.AccumuloRangeGenerator: java.lang.Object processExpression(org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc,java.lang.Object[])>",
    "<org.apache.hadoop.hive.accumulo.mr.HiveAccumuloTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.accumulo.serde.AccumuloSerDeParameters: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,java.lang.String)>",
    "<org.apache.hadoop.hive.accumulo.HiveAccumuloHelper: void mergeTokenIntoJobConf(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.security.token.Token)>",
    "<org.apache.hadoop.hive.accumulo.serde.AccumuloRowSerializer: void writeString(org.apache.hadoop.hive.serde2.ByteStream$Output,java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector)>",
    "<org.apache.hadoop.hive.accumulo.predicate.PrimitiveComparisonFilter: boolean filter(org.apache.hadoop.io.Text,java.util.List,java.util.List)>"
  ]
}