{
  "2.0.0-alpha3": [
    "<org.apache.hadoop.hbase.snapshot.ExportSnapshot: int doWork()>",
    "<org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportMapper: org.apache.hadoop.hbase.io.FileLink getFileLink(org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.regionserver.CompactionTool$CompactionWorker: org.apache.hadoop.hbase.regionserver.HStore getStore(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.hbase.client.TableDescriptor,org.apache.hadoop.hbase.HRegionInfo,java.lang.String,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication$Verifier: void map(org.apache.hadoop.hbase.io.ImmutableBytesWritable,org.apache.hadoop.hbase.client.Result,org.apache.hadoop.mapreduce.Mapper$Context)>",
    "<org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$RecordReader: void initialize(org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl$InputSplit,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.mapreduce.HFileInputFormat$HFileRecordReader: void initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl: void setInput(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hbase.snapshot.ExportSnapshot: void verifySnapshot(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hbase.snapshot.ExportSnapshot$1: void storeFile(org.apache.hadoop.hbase.HRegionInfo,java.lang.String,org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos$SnapshotRegionManifest$StoreFile)>",
    "<org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALRecordReader: boolean nextKeyValue()>",
    "<org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormatImpl: void restoreSnapshots(org.apache.hadoop.conf.Configuration,java.util.Map,org.apache.hadoop.fs.FileSystem)>",
    "<org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormatImpl: void setInput(org.apache.hadoop.conf.Configuration,java.util.Map,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2$1: org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2$WriterLength getNewWriter(byte[],byte[],org.apache.hadoop.conf.Configuration,java.net.InetSocketAddress[])>",
    "<org.apache.hadoop.hbase.mapreduce.WALInputFormat$WALRecordReader: void openReader(org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormatImpl: void restoreSnapshot(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FileSystem)>",
    "<org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl: java.util.List getSplits(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.mapreduce.TableSnapshotInputFormatImpl: java.util.List getSplits(org.apache.hadoop.hbase.client.Scan,org.apache.hadoop.hbase.snapshot.SnapshotManifest,java.util.List,org.apache.hadoop.fs.Path,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.snapshot.ExportSnapshot: java.util.List getSnapshotFiles(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hbase.mapreduce.MultiTableSnapshotInputFormatImpl: java.util.List getSplits(org.apache.hadoop.conf.Configuration)>"
  ],
  "2.0.0-alpha4": [
    "<org.apache.hadoop.hbase.snapshot.ExportSnapshot: int doWork()>",
    "<org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportMapper: void setup(org.apache.hadoop.mapreduce.Mapper$Context)>",
    "<org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportMapper: void copyData(org.apache.hadoop.mapreduce.Mapper$Context,org.apache.hadoop.fs.Path,java.io.InputStream,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.FSDataOutputStream,long)>",
    "<org.apache.hadoop.hbase.mapreduce.CopyTable: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.mapreduce.HFileInputFormat$HFileRecordReader: void initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<org.apache.hadoop.hbase.mapreduce.HashTable: int run(java.lang.String[])>",
    "<org.apache.hadoop.hbase.snapshot.ExportSnapshot$ExportSnapshotInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<org.apache.hadoop.hbase.regionserver.CompactionTool$CompactionWorker: org.apache.hadoop.hbase.regionserver.HStore getStore(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,org.apache.hadoop.hbase.client.TableDescriptor,org.apache.hadoop.hbase.client.RegionInfo,java.lang.String,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil: void addDependencyJarsForClasses(org.apache.hadoop.conf.Configuration,java.lang.Class[])>",
    "<org.apache.hadoop.hbase.mapreduce.WALPlayer: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.mapreduce.Export: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.mapreduce.Import: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.mapreduce.TableInputFormatBase: org.apache.hadoop.mapreduce.RecordReader createRecordReader(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<org.apache.hadoop.hbase.mapreduce.CopyTable: int run(java.lang.String[])>",
    "<org.apache.hadoop.hbase.mapreduce.PutSortReducer: void reduce(org.apache.hadoop.hbase.io.ImmutableBytesWritable,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>",
    "<org.apache.hadoop.hbase.mapreduce.Import: org.apache.hadoop.mapreduce.Job createSubmittableJob(org.apache.hadoop.conf.Configuration,java.lang.String[])>",
    "<org.apache.hadoop.hbase.mapreduce.SyncTable: int run(java.lang.String[])>",
    "<org.apache.hadoop.hbase.mapreduce.ImportTsv: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.mapreduce.HashTable$TableHash: void writePartitionFile(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hbase.mapreduce.CellCounter: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.List,boolean)>",
    "<org.apache.hadoop.hbase.mapreduce.HashTable$TableHash$Reader: void openHashFile()>",
    "<org.apache.hadoop.hbase.mapreduce.TextSortReducer: void reduce(org.apache.hadoop.hbase.io.ImmutableBytesWritable,java.lang.Iterable,org.apache.hadoop.mapreduce.Reducer$Context)>",
    "<org.apache.hadoop.hbase.util.MapreduceDependencyClasspathTool: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.List,boolean)>",
    "<org.apache.hadoop.hbase.mapreduce.CopyTable: org.apache.hadoop.mapreduce.Job createSubmittableJob(java.lang.String[])>",
    "<org.apache.hadoop.hbase.regionserver.CompactionTool$CompactionMapper: void setup(org.apache.hadoop.mapreduce.Mapper$Context)>",
    "<org.apache.hadoop.hbase.regionserver.CompactionTool: int run(java.lang.String[])>",
    "<org.apache.hadoop.hbase.mapreduce.HashTable$TableHash: void readPartitionFile(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hbase.mapred.RowCounter: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.mapreduce.SyncTable: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.mapreduce.RowCounter: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.mapreduce.HashTable: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.snapshot.ExportSnapshot: java.util.List getBalancedSplits(java.util.List,int)>",
    "<org.apache.hadoop.hbase.mapreduce.MultithreadedTableMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<org.apache.hadoop.hbase.regionserver.CompactionTool: void main(java.lang.String[])>"
  ]
}