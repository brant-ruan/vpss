{
  "2.0.0-alpha3": [
    "<org.apache.hadoop.hbase.backup.HBackupFileSystem: org.apache.hadoop.fs.Path getManifestPath(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.String)>",
    "<org.apache.hadoop.hbase.backup.util.BackupUtils: boolean checkPathExist(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.util.BackupUtils: java.util.List getWALFilesOlderThan(org.apache.hadoop.conf.Configuration,java.util.HashMap)>",
    "<org.apache.hadoop.hbase.backup.impl.BackupAdminImpl: int deleteBackup(java.lang.String,org.apache.hadoop.hbase.backup.impl.BackupSystemTable)>",
    "<org.apache.hadoop.hbase.backup.mapreduce.MapReduceHFileSplitterJob: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.backup.util.RestoreTool: void incrementalRestoreTable(org.apache.hadoop.hbase.client.Connection,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path[],org.apache.hadoop.hbase.TableName[],org.apache.hadoop.hbase.TableName[],java.lang.String)>",
    "<org.apache.hadoop.hbase.backup.util.RestoreTool: byte[][] generateBoundaryKeys(java.util.ArrayList)>",
    "<org.apache.hadoop.hbase.backup.util.BackupUtils: org.apache.hadoop.fs.Path getBulkOutputDir(java.lang.String,org.apache.hadoop.conf.Configuration,boolean)>",
    "<org.apache.hadoop.hbase.backup.impl.BackupAdminImpl: java.lang.String backupTables(org.apache.hadoop.hbase.backup.BackupRequest)>",
    "<org.apache.hadoop.hbase.backup.impl.BackupManifest: void store(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.impl.TableBackupClient: void cleanupTargetDir(org.apache.hadoop.hbase.backup.BackupInfo,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.impl.TableBackupClient: void cleanupExportSnapshotLog(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.impl.IncrementalBackupManager: java.util.List getLogFilesForNewBackup(java.util.HashMap,java.util.HashMap,org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<org.apache.hadoop.hbase.backup.util.BackupUtils: void cleanupHLogDir(org.apache.hadoop.hbase.backup.BackupInfo,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.impl.IncrementalTableBackupClient: void deleteBulkLoadDirectory()>",
    "<org.apache.hadoop.hbase.backup.impl.IncrementalTableBackupClient: java.util.List filterMissingFiles(java.util.List)>",
    "<org.apache.hadoop.hbase.backup.RestoreDriver: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.backup.impl.TableBackupClient: void cleanupDistCpLog(org.apache.hadoop.hbase.backup.BackupInfo,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.util.RestoreTool: void createAndRestoreTable(org.apache.hadoop.hbase.client.Connection,org.apache.hadoop.hbase.TableName,org.apache.hadoop.hbase.TableName,org.apache.hadoop.fs.Path,boolean,java.lang.String)>",
    "<org.apache.hadoop.hbase.backup.impl.IncrementalTableBackupClient: java.util.Map[] handleBulkLoad(java.util.List)>",
    "<org.apache.hadoop.hbase.backup.BackupDriver: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.backup.util.BackupUtils: void cleanupTargetDir(org.apache.hadoop.hbase.backup.BackupInfo,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.impl.BackupManifest: void <init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hbase.backup.impl.BackupAdminImpl: void cleanupBackupDir(org.apache.hadoop.hbase.backup.BackupInfo,org.apache.hadoop.hbase.TableName,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.util.BackupUtils: java.util.List getHistory(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hbase.backup.impl.BackupCommands$CreateCommand: boolean verifyPath(java.lang.String)>",
    "<org.apache.hadoop.hbase.backup.util.BackupUtils: void copyTableRegionInfo(org.apache.hadoop.hbase.client.Connection,org.apache.hadoop.hbase.backup.BackupInfo,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.mapreduce.MapReduceBackupCopyJob: int copy(org.apache.hadoop.hbase.backup.BackupInfo,org.apache.hadoop.hbase.backup.impl.BackupManager,org.apache.hadoop.conf.Configuration,org.apache.hadoop.hbase.backup.BackupType,java.lang.String[])>",
    "<org.apache.hadoop.hbase.backup.impl.BackupAdminImpl: void checkIfValidForMerge(java.lang.String[],org.apache.hadoop.hbase.backup.impl.BackupSystemTable)>",
    "<org.apache.hadoop.hbase.backup.mapreduce.MapReduceBackupMergeJob: void run(java.lang.String[])>",
    "<org.apache.hadoop.hbase.backup.util.RestoreTool: void <init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.String)>"
  ],
  "2.0.0-alpha4": [
    "<org.apache.hadoop.hbase.backup.HBackupFileSystem: org.apache.hadoop.fs.Path getManifestPath(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.String)>",
    "<org.apache.hadoop.hbase.backup.util.BackupUtils: boolean checkPathExist(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.util.BackupUtils: java.util.List getWALFilesOlderThan(org.apache.hadoop.conf.Configuration,java.util.HashMap)>",
    "<org.apache.hadoop.hbase.backup.impl.BackupAdminImpl: int deleteBackup(java.lang.String,org.apache.hadoop.hbase.backup.impl.BackupSystemTable)>",
    "<org.apache.hadoop.hbase.backup.mapreduce.MapReduceHFileSplitterJob: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.backup.util.RestoreTool: void incrementalRestoreTable(org.apache.hadoop.hbase.client.Connection,org.apache.hadoop.fs.Path,org.apache.hadoop.fs.Path[],org.apache.hadoop.hbase.TableName[],org.apache.hadoop.hbase.TableName[],java.lang.String)>",
    "<org.apache.hadoop.hbase.backup.util.RestoreTool: byte[][] generateBoundaryKeys(java.util.ArrayList)>",
    "<org.apache.hadoop.hbase.backup.util.BackupUtils: org.apache.hadoop.fs.Path getBulkOutputDir(java.lang.String,org.apache.hadoop.conf.Configuration,boolean)>",
    "<org.apache.hadoop.hbase.backup.impl.BackupAdminImpl: java.lang.String backupTables(org.apache.hadoop.hbase.backup.BackupRequest)>",
    "<org.apache.hadoop.hbase.backup.impl.BackupManifest: void store(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.impl.TableBackupClient: void cleanupTargetDir(org.apache.hadoop.hbase.backup.BackupInfo,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.util.BackupUtils: void cleanupHLogDir(org.apache.hadoop.hbase.backup.BackupInfo,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.impl.IncrementalTableBackupClient: void deleteBulkLoadDirectory()>",
    "<org.apache.hadoop.hbase.backup.impl.IncrementalTableBackupClient: java.util.List filterMissingFiles(java.util.List)>",
    "<org.apache.hadoop.hbase.backup.RestoreDriver: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.backup.impl.TableBackupClient: void cleanupDistCpLog(org.apache.hadoop.hbase.backup.BackupInfo,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.util.RestoreTool: void createAndRestoreTable(org.apache.hadoop.hbase.client.Connection,org.apache.hadoop.hbase.TableName,org.apache.hadoop.hbase.TableName,org.apache.hadoop.fs.Path,boolean,java.lang.String)>",
    "<org.apache.hadoop.hbase.backup.impl.IncrementalTableBackupClient: java.util.Map[] handleBulkLoad(java.util.List)>",
    "<org.apache.hadoop.hbase.backup.BackupDriver: void main(java.lang.String[])>",
    "<org.apache.hadoop.hbase.backup.util.BackupUtils: void cleanupTargetDir(org.apache.hadoop.hbase.backup.BackupInfo,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.impl.BackupManifest: void <init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hbase.backup.impl.BackupAdminImpl: void cleanupBackupDir(org.apache.hadoop.hbase.backup.BackupInfo,org.apache.hadoop.hbase.TableName,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.util.BackupUtils: java.util.List getHistory(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hbase.backup.impl.BackupCommands$CreateCommand: boolean verifyPath(java.lang.String)>",
    "<org.apache.hadoop.hbase.backup.util.BackupUtils: void copyTableRegionInfo(org.apache.hadoop.hbase.client.Connection,org.apache.hadoop.hbase.backup.BackupInfo,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hbase.backup.mapreduce.MapReduceBackupCopyJob$BackupDistCp: org.apache.hadoop.io.SequenceFile$Writer getWriter(org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hbase.backup.mapreduce.MapReduceBackupCopyJob: int copy(org.apache.hadoop.hbase.backup.BackupInfo,org.apache.hadoop.hbase.backup.impl.BackupManager,org.apache.hadoop.conf.Configuration,org.apache.hadoop.hbase.backup.BackupType,java.lang.String[])>",
    "<org.apache.hadoop.hbase.backup.impl.BackupAdminImpl: void checkIfValidForMerge(java.lang.String[],org.apache.hadoop.hbase.backup.impl.BackupSystemTable)>",
    "<org.apache.hadoop.hbase.backup.mapreduce.MapReduceBackupMergeJob: void run(java.lang.String[])>",
    "<org.apache.hadoop.hbase.backup.util.RestoreTool: void <init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.lang.String)>"
  ]
}