{
  "4.10.0-HBase-1.1": [
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.9.0-HBase-0.98": [
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.AbstractBulkLoadTool: int submitJob(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,java.util.List,boolean)>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitBeforePONR(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[],java.util.List)>",
    "<org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitAfterPONR(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureSubmittableJobUsingDirectApi(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureRunnableJobUsingBulkLoad(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompleteSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.hbase.index.Indexer: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.HRegion,org.apache.hadoop.hbase.regionserver.HRegion)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile)>"
  ],
  "4.11.0-HBase-1.1": [
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.8.1-HBase-0.98": [
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.AbstractBulkLoadTool: int submitJob(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,java.util.List,boolean)>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitBeforePONR(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[],java.util.List)>",
    "<org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitAfterPONR(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureSubmittableJobUsingDirectApi(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureRunnableJobUsingBulkLoad(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompleteSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.hbase.index.Indexer: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.HRegion,org.apache.hadoop.hbase.regionserver.HRegion)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile)>"
  ],
  "4.14.0-HBase-1.1": [
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.schema.stats.StatisticsCollectorFactory: boolean statisticsEnabled(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.util.SchemaUtil: boolean isNamespaceMappingEnabled(org.apache.phoenix.schema.PTableType,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.schema.stats.DefaultStatisticsCollector: void <init>(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment,java.lang.String,long,byte[],byte[],byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.11.0-HBase-0.98": [
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitBeforePONR(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[],java.util.List)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitAfterPONR(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompleteSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.hbase.index.Indexer: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.HRegion,org.apache.hadoop.hbase.regionserver.HRegion)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile)>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.13.0-HBase-1.3": [
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.8.0-HBase-0.98": [
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.AbstractBulkLoadTool: int submitJob(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,java.util.List,boolean)>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitBeforePONR(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[],java.util.List)>",
    "<org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitAfterPONR(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.query.ConnectionQueryServicesImpl: void openConnection()>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureSubmittableJobUsingDirectApi(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureRunnableJobUsingBulkLoad(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompleteSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.hbase.index.Indexer: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.HRegion,org.apache.hadoop.hbase.regionserver.HRegion)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile)>"
  ],
  "4.14.0-HBase-1.2": [
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.schema.stats.StatisticsCollectorFactory: boolean statisticsEnabled(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.util.SchemaUtil: boolean isNamespaceMappingEnabled(org.apache.phoenix.schema.PTableType,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.schema.stats.DefaultStatisticsCollector: void <init>(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment,java.lang.String,long,byte[],byte[],byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.15.0-HBase-1.3": [
    "<org.apache.phoenix.tool.PhoenixCanaryTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.schema.stats.StatisticsCollectorFactory: boolean statisticsEnabled(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.OrphanViewTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.util.SchemaUtil: boolean isNamespaceMappingEnabled(org.apache.phoenix.schema.PTableType,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexUpgradeTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForServerBuildIndex()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAsyncIndex()>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.schema.stats.DefaultStatisticsCollector: void <init>(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment,java.lang.String,long,byte[],byte[],byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.8.0-HBase-1.0": [
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.AbstractBulkLoadTool: int submitJob(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,java.util.List,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureRunnableJobUsingBulkLoad(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.query.ConnectionQueryServicesImpl: void openConnection()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureSubmittableJobUsingDirectApi(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>"
  ],
  "4.14.2-HBase-1.3": [
    "<org.apache.phoenix.tool.PhoenixCanaryTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.schema.stats.StatisticsCollectorFactory: boolean statisticsEnabled(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.OrphanViewTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.util.SchemaUtil: boolean isNamespaceMappingEnabled(org.apache.phoenix.schema.PTableType,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForServerBuildIndex()>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.schema.stats.DefaultStatisticsCollector: void <init>(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment,java.lang.String,long,byte[],byte[],byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.13.1-HBase-1.2": [
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.11.0-HBase-1.2": [
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.13.1-HBase-0.98": [
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitBeforePONR(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[],java.util.List)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitAfterPONR(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompleteSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.hbase.index.Indexer: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.HRegion,org.apache.hadoop.hbase.regionserver.HRegion)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile)>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.8.1-HBase-1.0": [
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.AbstractBulkLoadTool: int submitJob(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,java.util.List,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureRunnableJobUsingBulkLoad(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureSubmittableJobUsingDirectApi(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>"
  ],
  "4.11.0-HBase-1.3": [
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.10.0-HBase-1.2": [
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.14.1-HBase-1.3": [
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.schema.stats.StatisticsCollectorFactory: boolean statisticsEnabled(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.util.SchemaUtil: boolean isNamespaceMappingEnabled(org.apache.phoenix.schema.PTableType,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.schema.stats.DefaultStatisticsCollector: void <init>(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment,java.lang.String,long,byte[],byte[],byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.9.0-HBase-1.2": [
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.AbstractBulkLoadTool: int submitJob(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,java.util.List,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureRunnableJobUsingBulkLoad(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureSubmittableJobUsingDirectApi(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>"
  ],
  "4.8.0-HBase-1.2": [
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.AbstractBulkLoadTool: int submitJob(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,java.util.List,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureRunnableJobUsingBulkLoad(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.query.ConnectionQueryServicesImpl: void openConnection()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureSubmittableJobUsingDirectApi(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>"
  ],
  "4.13.1-HBase-1.1": [
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.14.3-HBase-1.3": [
    "<org.apache.phoenix.tool.PhoenixCanaryTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.schema.stats.StatisticsCollectorFactory: boolean statisticsEnabled(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.OrphanViewTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.util.SchemaUtil: boolean isNamespaceMappingEnabled(org.apache.phoenix.schema.PTableType,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexUpgradeTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForServerBuildIndex()>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.schema.stats.DefaultStatisticsCollector: void <init>(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment,java.lang.String,long,byte[],byte[],byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.12.0-HBase-1.1": [
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.12.0-HBase-1.3": [
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.8.0-HBase-1.1": [
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.AbstractBulkLoadTool: int submitJob(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,java.util.List,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureRunnableJobUsingBulkLoad(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.query.ConnectionQueryServicesImpl: void openConnection()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureSubmittableJobUsingDirectApi(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>"
  ],
  "4.12.0-HBase-1.2": [
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.13.1-HBase-1.3": [
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.14.1-HBase-1.2": [
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.schema.stats.StatisticsCollectorFactory: boolean statisticsEnabled(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.util.SchemaUtil: boolean isNamespaceMappingEnabled(org.apache.phoenix.schema.PTableType,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.schema.stats.DefaultStatisticsCollector: void <init>(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment,java.lang.String,long,byte[],byte[],byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.9.0-HBase-1.1": [
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.AbstractBulkLoadTool: int submitJob(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,java.util.List,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureRunnableJobUsingBulkLoad(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureSubmittableJobUsingDirectApi(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>"
  ],
  "4.10.0-HBase-0.98": [
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitBeforePONR(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[],java.util.List)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitAfterPONR(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompleteSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.hbase.index.Indexer: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.HRegion,org.apache.hadoop.hbase.regionserver.HRegion)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile)>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.12.0-HBase-0.98": [
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitBeforePONR(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[],java.util.List)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitAfterPONR(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.hbase.index.Indexer: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompleteSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.hbase.index.Indexer: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.HRegion,org.apache.hadoop.hbase.regionserver.HRegion)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile)>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.13.0-HBase-0.98": [
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitBeforePONR(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[],java.util.List)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitAfterPONR(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompleteSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.hbase.index.Indexer: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.HRegion,org.apache.hadoop.hbase.regionserver.HRegion)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile)>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.14.1-HBase-1.1": [
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.schema.stats.StatisticsCollectorFactory: boolean statisticsEnabled(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.util.SchemaUtil: boolean isNamespaceMappingEnabled(org.apache.phoenix.schema.PTableType,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.schema.stats.DefaultStatisticsCollector: void <init>(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment,java.lang.String,long,byte[],byte[],byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.8.1-HBase-1.2": [
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.AbstractBulkLoadTool: int submitJob(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,java.util.List,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureRunnableJobUsingBulkLoad(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureSubmittableJobUsingDirectApi(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>"
  ],
  "4.14.1-HBase-0.98": [
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.schema.stats.StatisticsCollectorFactory: boolean statisticsEnabled(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitBeforePONR(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[],java.util.List)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitAfterPONR(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.util.SchemaUtil: boolean isNamespaceMappingEnabled(org.apache.phoenix.schema.PTableType,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompleteSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.hbase.index.Indexer: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.HRegion,org.apache.hadoop.hbase.regionserver.HRegion)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List)>",
    "<org.apache.phoenix.schema.stats.DefaultStatisticsCollector: void <init>(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment,java.lang.String,long,byte[],byte[],byte[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile)>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.14.0-HBase-1.3": [
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.schema.stats.StatisticsCollectorFactory: boolean statisticsEnabled(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.util.SchemaUtil: boolean isNamespaceMappingEnabled(org.apache.phoenix.schema.PTableType,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.schema.stats.DefaultStatisticsCollector: void <init>(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment,java.lang.String,long,byte[],byte[],byte[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.14.0-HBase-0.98": [
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preRollBackSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.schema.stats.StatisticsCollectorFactory: boolean statisticsEnabled(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitBeforePONR(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[],java.util.List)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: long getMaxRebuildAsyncDate(java.lang.String,java.util.List)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplitAfterPONR(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForPartialBuild(java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.ScanType,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList)>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: boolean isSameName(java.lang.String,java.lang.String,java.lang.String,java.lang.String)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.index.IndexScrutinyTool$JobFactory: org.apache.hadoop.fs.Path getOutputPath(org.apache.hadoop.conf.Configuration,java.lang.String,org.apache.phoenix.schema.PTable)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.util.SchemaUtil: boolean isNamespaceMappingEnabled(org.apache.phoenix.schema.PTableType,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.index.IndexTool$JobFactory: org.apache.hadoop.mapreduce.Job configureJobForAysncIndex(java.lang.String,java.lang.String,java.lang.String,boolean,boolean)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompleteSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,com.google.common.collect.ImmutableList,org.apache.hadoop.hbase.regionserver.compactions.CompactionRequest)>",
    "<org.apache.phoenix.hbase.index.Indexer: org.apache.hadoop.hbase.regionserver.InternalScanner preCompactScannerOpen(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List,org.apache.hadoop.hbase.regionserver.ScanType,long,org.apache.hadoop.hbase.regionserver.InternalScanner)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.HRegion,org.apache.hadoop.hbase.regionserver.HRegion)>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preSplit(org.apache.hadoop.hbase.coprocessor.ObserverContext,byte[])>",
    "<org.apache.phoenix.iterate.MapReduceParallelScanGrouper: java.util.List getRegionBoundaries(org.apache.phoenix.compile.StatementContext,byte[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void preCompactSelection(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,java.util.List)>",
    "<org.apache.phoenix.schema.stats.DefaultStatisticsCollector: void <init>(org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment,java.lang.String,long,byte[],byte[],byte[])>",
    "<org.apache.phoenix.coprocessor.DelegateRegionObserver: void postCompact(org.apache.hadoop.hbase.coprocessor.ObserverContext,org.apache.hadoop.hbase.regionserver.Store,org.apache.hadoop.hbase.regionserver.StoreFile)>",
    "<org.apache.phoenix.mapreduce.RegexBulkLoadTool: void main(java.lang.String[])>"
  ],
  "4.8.1-HBase-1.1": [
    "<org.apache.phoenix.mapreduce.index.IndexTool: int run(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableDeleteJarStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.automation.PhoenixMRJobSubmitter: void enableKeyTabSecurity()>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void configurePartitioner(org.apache.hadoop.mapreduce.Job,java.util.Set)>",
    "<org.apache.phoenix.mapreduce.AbstractBulkLoadTool: int submitJob(org.apache.hadoop.conf.Configuration,java.lang.String,java.lang.String,org.apache.hadoop.fs.Path,java.util.List,boolean)>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureRunnableJobUsingBulkLoad(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>",
    "<org.apache.phoenix.mapreduce.CsvBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.JsonBulkLoadTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo: org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo normalize(org.apache.phoenix.util.ReadOnlyProps,java.util.Properties)>",
    "<org.apache.phoenix.jdbc.PhoenixStatement$ExecutableAddJarsStatement$1: org.apache.phoenix.execute.MutationState execute()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void main(java.lang.String[])>",
    "<org.apache.phoenix.mapreduce.MultiHfileOutputFormat: void writePartitions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,java.util.Set)>",
    "<org.apache.phoenix.compile.ListJarsQueryPlan$1: org.apache.phoenix.schema.tuple.Tuple next()>",
    "<org.apache.phoenix.mapreduce.index.IndexTool: void configureSubmittableJobUsingDirectApi(org.apache.hadoop.mapreduce.Job,org.apache.hadoop.fs.Path,boolean)>"
  ]
}