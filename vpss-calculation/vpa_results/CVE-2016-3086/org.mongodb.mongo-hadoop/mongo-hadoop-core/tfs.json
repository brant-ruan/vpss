{
  "1.4-rc0": [
    "<com.mongodb.hadoop.splitter.BSONSplitter: void main(java.lang.String[])>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoRecordWriter: void <init>(java.util.List,org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void cleanupTemporaryFiles(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: boolean needsTaskCommit(org.apache.hadoop.mapreduce.TaskAttemptContext)>"
  ],
  "1.4.2": [
    "<com.mongodb.hadoop.splitter.BSONSplitter: void main(java.lang.String[])>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoRecordWriter: void <init>(java.util.List,org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void cleanupTemporaryFiles(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: boolean needsTaskCommit(org.apache.hadoop.mapreduce.TaskAttemptContext)>"
  ],
  "1.4.0": [
    "<com.mongodb.hadoop.splitter.BSONSplitter: void main(java.lang.String[])>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoRecordWriter: void <init>(java.util.List,org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void cleanupTemporaryFiles(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: boolean needsTaskCommit(org.apache.hadoop.mapreduce.TaskAttemptContext)>"
  ],
  "1.4.1": [
    "<com.mongodb.hadoop.splitter.BSONSplitter: void main(java.lang.String[])>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoRecordWriter: void <init>(java.util.List,org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void cleanupTemporaryFiles(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: boolean needsTaskCommit(org.apache.hadoop.mapreduce.TaskAttemptContext)>"
  ],
  "2.0.2": [
    "<com.mongodb.hadoop.output.MongoOutputCommitter: boolean needsTaskCommit(com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.mapreduce.JobContext,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.BSONFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: void main(java.lang.String[])>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void cleanupResources(com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.FileSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void commitTask(com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoRecordWriter: void <init>(com.mongodb.DBCollection,com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: int run(java.lang.String[])>",
    "<com.mongodb.hadoop.input.BSONFileRecordReader: void init(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.conf.Configuration)>",
    "<com.mongodb.hadoop.util.MongoConfigUtil: java.util.Properties readPropertiesFromFile(org.apache.hadoop.conf.Configuration,java.lang.String)>"
  ],
  "2.0.1": [
    "<com.mongodb.hadoop.output.MongoOutputCommitter: boolean needsTaskCommit(com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.mapreduce.JobContext,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.BSONFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: void main(java.lang.String[])>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void cleanupResources(com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.FileSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void commitTask(com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoRecordWriter: void <init>(com.mongodb.DBCollection,com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: int run(java.lang.String[])>",
    "<com.mongodb.hadoop.input.BSONFileRecordReader: void init(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.conf.Configuration)>",
    "<com.mongodb.hadoop.util.MongoConfigUtil: java.util.Properties readPropertiesFromFile(org.apache.hadoop.conf.Configuration,java.lang.String)>"
  ],
  "2.0.0": [
    "<com.mongodb.hadoop.output.MongoOutputCommitter: boolean needsTaskCommit(com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.mapreduce.JobContext,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.BSONFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: void main(java.lang.String[])>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void cleanupResources(com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.FileSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void commitTask(com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoRecordWriter: void <init>(com.mongodb.DBCollection,com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: int run(java.lang.String[])>",
    "<com.mongodb.hadoop.input.BSONFileRecordReader: void init(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.conf.Configuration)>",
    "<com.mongodb.hadoop.util.MongoConfigUtil: java.util.Properties readPropertiesFromFile(org.apache.hadoop.conf.Configuration,java.lang.String)>"
  ],
  "1.5.0-rc0": [
    "<com.mongodb.hadoop.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.mapreduce.JobContext,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.BSONFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.mongodb.hadoop.input.BSONFileRecordReader: void initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: void main(java.lang.String[])>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoRecordWriter: void <init>(java.util.List,org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.FileSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: int run(java.lang.String[])>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void cleanupTemporaryFiles(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.util.MongoConfigUtil: java.util.Properties readPropertiesFromFile(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: boolean needsTaskCommit(org.apache.hadoop.mapreduce.TaskAttemptContext)>"
  ],
  "1.5.0": [
    "<com.mongodb.hadoop.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.mapreduce.JobContext,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.BSONFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.mongodb.hadoop.input.BSONFileRecordReader: void initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: void main(java.lang.String[])>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoRecordWriter: void <init>(java.util.List,org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.FileSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: int run(java.lang.String[])>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void cleanupTemporaryFiles(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.util.MongoConfigUtil: java.util.Properties readPropertiesFromFile(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: boolean needsTaskCommit(org.apache.hadoop.mapreduce.TaskAttemptContext)>"
  ],
  "1.5.2": [
    "<com.mongodb.hadoop.util.MongoConfigUtil: java.util.Properties readPropertiesFromFile(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.mongodb.hadoop.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.mapreduce.JobContext,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.BSONFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.mongodb.hadoop.input.BSONFileRecordReader: void initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: void main(java.lang.String[])>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoRecordWriter: void <init>(java.util.List,org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.FileSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: int run(java.lang.String[])>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void cleanupResources(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: boolean needsTaskCommit(org.apache.hadoop.mapreduce.TaskAttemptContext)>"
  ],
  "1.5.1": [
    "<com.mongodb.hadoop.util.MongoConfigUtil: java.util.Properties readPropertiesFromFile(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.mongodb.hadoop.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.mapreduce.JobContext,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.BSONFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.mongodb.hadoop.input.BSONFileRecordReader: void initialize(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: void main(java.lang.String[])>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoRecordWriter: void <init>(java.util.List,org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.FileSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: int run(java.lang.String[])>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void cleanupResources(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: boolean needsTaskCommit(org.apache.hadoop.mapreduce.TaskAttemptContext)>"
  ],
  "2.0.0-rc0": [
    "<com.mongodb.hadoop.output.MongoOutputCommitter: boolean needsTaskCommit(com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.mapreduce.JobContext,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.BSONFileInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: void main(java.lang.String[])>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void cleanupResources(com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.FileSplit[] getSplits(org.apache.hadoop.mapred.JobConf,int)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<com.mongodb.hadoop.output.MongoOutputCommitter: void commitTask(com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.output.MongoRecordWriter: void <init>(com.mongodb.DBCollection,com.mongodb.hadoop.util.CompatUtils$TaskAttemptContext)>",
    "<com.mongodb.hadoop.mapred.BSONFileInputFormat: boolean isSplitable(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path)>",
    "<com.mongodb.hadoop.splitter.BSONSplitter: int run(java.lang.String[])>",
    "<com.mongodb.hadoop.input.BSONFileRecordReader: void init(org.apache.hadoop.mapreduce.InputSplit,org.apache.hadoop.conf.Configuration)>",
    "<com.mongodb.hadoop.util.MongoConfigUtil: java.util.Properties readPropertiesFromFile(org.apache.hadoop.conf.Configuration,java.lang.String)>"
  ]
}