{
  "1.2.0": [
    "<com.landoop.streamreactor.connect.hive.orc.package$: org.apache.orc.Writer createOrcWriter(org.apache.hadoop.fs.Path,org.apache.orc.TypeDescription,com.landoop.streamreactor.connect.hive.OrcSinkConfig,org.apache.hadoop.fs.FileSystem)>",
    "<com.landoop.streamreactor.connect.hive.package$: org.apache.hadoop.hive.metastore.api.Table createTable(com.landoop.streamreactor.connect.hive.DatabaseName,com.landoop.streamreactor.connect.hive.TableName,org.apache.kafka.connect.data.Schema,scala.collection.Seq,scala.Option,com.landoop.streamreactor.connect.hive.formats.HiveFormat,org.apache.hadoop.hive.metastore.IMetaStoreClient,org.apache.hadoop.fs.FileSystem)>",
    "<com.landoop.streamreactor.connect.hive.source.HiveSourceTask: void start(java.util.Map)>",
    "<com.landoop.streamreactor.connect.hive.sink.HiveSinkTask: void start(java.util.Map)>",
    "<com.landoop.streamreactor.connect.hive.package$$anonfun$5: org.apache.hadoop.hive.metastore.api.FieldSchema apply(com.landoop.streamreactor.connect.hive.PartitionField)>",
    "<com.landoop.streamreactor.connect.hive.sink.partitioning.DynamicPartitionHandler: void com$landoop$streamreactor$connect$hive$sink$partitioning$DynamicPartitionHandler$$create$1(org.apache.hadoop.fs.Path,org.apache.hadoop.hive.metastore.api.Table,com.landoop.streamreactor.connect.hive.Partition,com.landoop.streamreactor.connect.hive.DatabaseName,com.landoop.streamreactor.connect.hive.TableName,org.apache.hadoop.hive.metastore.IMetaStoreClient)>",
    "<com.landoop.streamreactor.connect.hive.HiveSchemas$: org.apache.hadoop.hive.metastore.api.FieldSchema toFieldSchema(org.apache.kafka.connect.data.Field)>",
    "<com.landoop.streamreactor.connect.hive.orc.OrcSource: void <init>(org.apache.hadoop.fs.Path,com.landoop.streamreactor.connect.hive.OrcSourceConfig,org.apache.hadoop.fs.FileSystem)>"
  ]
}