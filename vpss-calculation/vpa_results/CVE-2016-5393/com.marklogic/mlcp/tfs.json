{
  "9.0.7.2": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "10.0.6.1": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.mapreduce.ContentOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.ContentReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.BinaryWriter: void write(com.marklogic.mapreduce.DocumentURI,org.apache.hadoop.io.BytesWritable)>",
    "<com.marklogic.mapreduce.examples.WikiLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementAttributeValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.CustomQuery: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.mapreduce.test.ValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.BinaryLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.WordsTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.FCheck: void checkTreeIndex(java.io.File)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElemValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.RevisionGrouper: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.KeyValueOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTreeJSON: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.MarkLogicOutputFormat: com.marklogic.mapreduce.utilities.TextArrayWritable getHosts(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.ContentOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getForestStatusMap(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.test.ElemAttrValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.HelloWorld: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: int run(java.lang.String[])>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.PropertyOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.BinaryReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.ContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>",
    "<com.marklogic.mapreduce.test.ValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.LinkCountCooccurrences: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountHDFS: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCount: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInDoc: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountValue: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MultithreadedZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentWriter: com.marklogic.xcc.Content createContent(com.marklogic.mapreduce.DocumentURI,java.lang.Object)>",
    "<com.marklogic.mapreduce.examples.ZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInProperty: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.NodeOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>"
  ],
  "10.0.6": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.mapreduce.ContentOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.ContentReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.BinaryWriter: void write(com.marklogic.mapreduce.DocumentURI,org.apache.hadoop.io.BytesWritable)>",
    "<com.marklogic.mapreduce.examples.WikiLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementAttributeValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.CustomQuery: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.mapreduce.test.ValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.BinaryLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.WordsTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.FCheck: void checkTreeIndex(java.io.File)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElemValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.RevisionGrouper: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.KeyValueOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTreeJSON: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.MarkLogicOutputFormat: com.marklogic.mapreduce.utilities.TextArrayWritable getHosts(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.ContentOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getForestStatusMap(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.test.ElemAttrValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.HelloWorld: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: int run(java.lang.String[])>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.PropertyOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.BinaryReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.ContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>",
    "<com.marklogic.mapreduce.test.ValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.LinkCountCooccurrences: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountHDFS: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCount: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInDoc: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountValue: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MultithreadedZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentWriter: com.marklogic.xcc.Content createContent(com.marklogic.mapreduce.DocumentURI,java.lang.Object)>",
    "<com.marklogic.mapreduce.examples.ZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInProperty: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.NodeOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>"
  ],
  "10.0.4.2": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "10.0.1": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.12": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.4": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "10.0.4": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.1": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.2": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.7": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.8.2": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.10.2": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "10.0.3": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.11": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.10": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "10.0.5": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.mapreduce.KeyValueOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.mapreduce.examples.ContentReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.BinaryWriter: void write(com.marklogic.mapreduce.DocumentURI,org.apache.hadoop.io.BytesWritable)>",
    "<com.marklogic.mapreduce.examples.WikiLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementAttributeValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.CustomQuery: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.mapreduce.test.ValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.BinaryLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.WordsTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.FCheck: void checkTreeIndex(java.io.File)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElemValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.RevisionGrouper: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTreeJSON: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.MarkLogicOutputFormat: com.marklogic.mapreduce.utilities.TextArrayWritable getHosts(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.ContentOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getForestStatusMap(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.test.ElemAttrValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.HelloWorld: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: int run(java.lang.String[])>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.NodeOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.examples.BinaryReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.PropertyOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.mapreduce.examples.ContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountCooccurrences: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountHDFS: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCount: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInDoc: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountValue: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MultithreadedZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentWriter: com.marklogic.xcc.Content createContent(com.marklogic.mapreduce.DocumentURI,java.lang.Object)>",
    "<com.marklogic.mapreduce.examples.ZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInProperty: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.8": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.5": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.6": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.13": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.mapreduce.KeyValueOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.mapreduce.examples.ContentReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.BinaryWriter: void write(com.marklogic.mapreduce.DocumentURI,org.apache.hadoop.io.BytesWritable)>",
    "<com.marklogic.mapreduce.examples.WikiLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementAttributeValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.CustomQuery: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.mapreduce.test.ValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.BinaryLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.WordsTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.FCheck: void checkTreeIndex(java.io.File)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElemValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.RevisionGrouper: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTreeJSON: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.MarkLogicOutputFormat: com.marklogic.mapreduce.utilities.TextArrayWritable getHosts(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.ContentOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getForestStatusMap(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.test.ElemAttrValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.HelloWorld: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: int run(java.lang.String[])>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.NodeOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.examples.BinaryReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.PropertyOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.mapreduce.examples.ContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountCooccurrences: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountHDFS: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCount: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInDoc: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountValue: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MultithreadedZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentWriter: com.marklogic.xcc.Content createContent(com.marklogic.mapreduce.DocumentURI,java.lang.Object)>",
    "<com.marklogic.mapreduce.examples.ZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInProperty: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "10.0.6.2": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.mapreduce.ContentOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.ContentReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.BinaryWriter: void write(com.marklogic.mapreduce.DocumentURI,org.apache.hadoop.io.BytesWritable)>",
    "<com.marklogic.mapreduce.examples.WikiLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementAttributeValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.CustomQuery: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.mapreduce.test.ValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.BinaryLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.WordsTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.FCheck: void checkTreeIndex(java.io.File)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElemValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.RevisionGrouper: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.KeyValueOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTreeJSON: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.MarkLogicOutputFormat: com.marklogic.mapreduce.utilities.TextArrayWritable getHosts(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.ContentOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getForestStatusMap(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.test.ElemAttrValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.HelloWorld: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: int run(java.lang.String[])>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.PropertyOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.BinaryReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.ContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>",
    "<com.marklogic.mapreduce.test.ValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.LinkCountCooccurrences: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountHDFS: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCount: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInDoc: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountValue: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MultithreadedZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentWriter: com.marklogic.xcc.Content createContent(com.marklogic.mapreduce.DocumentURI,java.lang.Object)>",
    "<com.marklogic.mapreduce.examples.ZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInProperty: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.NodeOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>"
  ],
  "10.0.2": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.3": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "10.0.5.2": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.mapreduce.KeyValueOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.mapreduce.examples.ContentReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.BinaryWriter: void write(com.marklogic.mapreduce.DocumentURI,org.apache.hadoop.io.BytesWritable)>",
    "<com.marklogic.mapreduce.examples.WikiLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementAttributeValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.CustomQuery: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.mapreduce.test.ValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.BinaryLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.WordsTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.FCheck: void checkTreeIndex(java.io.File)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElemValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.RevisionGrouper: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTreeJSON: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.MarkLogicOutputFormat: com.marklogic.mapreduce.utilities.TextArrayWritable getHosts(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.ContentOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getForestStatusMap(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.test.ElemAttrValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.HelloWorld: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: int run(java.lang.String[])>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.NodeOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.examples.BinaryReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.PropertyOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.mapreduce.examples.ContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountCooccurrences: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountHDFS: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCount: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInDoc: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountValue: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MultithreadedZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentWriter: com.marklogic.xcc.Content createContent(com.marklogic.mapreduce.DocumentURI,java.lang.Object)>",
    "<com.marklogic.mapreduce.examples.ZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInProperty: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.9": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "10.0.8.2": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.mapreduce.ContentOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.ContentReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.BinaryWriter: void write(com.marklogic.mapreduce.DocumentURI,org.apache.hadoop.io.BytesWritable)>",
    "<com.marklogic.mapreduce.test.ElementAttributeValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.CustomQuery: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.mapreduce.test.ValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.BinaryLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.WordsTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.FCheck: void checkTreeIndex(java.io.File)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElemValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.RevisionGrouper: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.KeyValueOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTreeJSON: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getOutputContentSource(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.MarkLogicOutputFormat: com.marklogic.mapreduce.utilities.TextArrayWritable getHosts(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.Command: void applyModuleConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.ContentOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getForestStatusMap(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.test.ElemAttrValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.HelloWorld: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: int run(java.lang.String[])>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.PropertyOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.BinaryReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.ContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>",
    "<com.marklogic.mapreduce.test.ValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.LinkCountCooccurrences: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountHDFS: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCount: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInDoc: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountValue: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MultithreadedZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentWriter: com.marklogic.xcc.Content createContent(com.marklogic.mapreduce.DocumentURI,java.lang.Object)>",
    "<com.marklogic.mapreduce.examples.ZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInProperty: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.Command: boolean isStreaming(org.apache.commons.cli.CommandLine,org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.NodeOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>"
  ],
  "10.0.8": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.mapreduce.ContentOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.ContentReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.BinaryWriter: void write(com.marklogic.mapreduce.DocumentURI,org.apache.hadoop.io.BytesWritable)>",
    "<com.marklogic.mapreduce.test.ElementAttributeValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.CustomQuery: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.mapreduce.test.ValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.BinaryLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.WordsTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.FCheck: void checkTreeIndex(java.io.File)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElemValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.RevisionGrouper: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.KeyValueOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTreeJSON: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getOutputContentSource(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.MarkLogicOutputFormat: com.marklogic.mapreduce.utilities.TextArrayWritable getHosts(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.Command: void applyModuleConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.ContentOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getForestStatusMap(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.test.ElemAttrValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.HelloWorld: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: int run(java.lang.String[])>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.PropertyOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.BinaryReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.ContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>",
    "<com.marklogic.mapreduce.test.ValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.LinkCountCooccurrences: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountHDFS: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCount: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInDoc: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountValue: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MultithreadedZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentWriter: com.marklogic.xcc.Content createContent(com.marklogic.mapreduce.DocumentURI,java.lang.Object)>",
    "<com.marklogic.mapreduce.examples.ZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInProperty: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.Command: boolean isStreaming(org.apache.commons.cli.CommandLine,org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.NodeOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>"
  ],
  "9.0.13.8": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.mapreduce.KeyValueOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.mapreduce.examples.ContentReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.BinaryWriter: void write(com.marklogic.mapreduce.DocumentURI,org.apache.hadoop.io.BytesWritable)>",
    "<com.marklogic.mapreduce.test.ElementAttributeValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.CustomQuery: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.mapreduce.test.ValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.BinaryLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.WordsTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.FCheck: void checkTreeIndex(java.io.File)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElemValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.RevisionGrouper: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTreeJSON: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getOutputContentSource(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.MarkLogicOutputFormat: com.marklogic.mapreduce.utilities.TextArrayWritable getHosts(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.Command: void applyModuleConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.ContentOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getForestStatusMap(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.test.ElemAttrValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.HelloWorld: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: int run(java.lang.String[])>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.NodeOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.examples.BinaryReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.PropertyOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.mapreduce.examples.ContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountCooccurrences: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountHDFS: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCount: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInDoc: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountValue: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MultithreadedZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentWriter: com.marklogic.xcc.Content createContent(com.marklogic.mapreduce.DocumentURI,java.lang.Object)>",
    "<com.marklogic.mapreduce.examples.ZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInProperty: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.Command: boolean isStreaming(org.apache.commons.cli.CommandLine,org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "9.0.13.7": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.mapreduce.KeyValueOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.mapreduce.examples.ContentReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.BinaryWriter: void write(com.marklogic.mapreduce.DocumentURI,org.apache.hadoop.io.BytesWritable)>",
    "<com.marklogic.mapreduce.test.ElementAttributeValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.CustomQuery: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.mapreduce.test.ValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.BinaryLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.WordsTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.FCheck: void checkTreeIndex(java.io.File)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElemValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.RevisionGrouper: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTreeJSON: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getOutputContentSource(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.MarkLogicOutputFormat: com.marklogic.mapreduce.utilities.TextArrayWritable getHosts(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.Command: void applyModuleConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.ContentOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getForestStatusMap(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.test.ElemAttrValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.HelloWorld: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: int run(java.lang.String[])>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.NodeOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.examples.BinaryReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.PropertyOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.mapreduce.examples.ContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource)>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountCooccurrences: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountHDFS: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCount: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInDoc: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountValue: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MultithreadedZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentWriter: com.marklogic.xcc.Content createContent(com.marklogic.mapreduce.DocumentURI,java.lang.Object)>",
    "<com.marklogic.mapreduce.examples.ZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInProperty: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.Command: boolean isStreaming(org.apache.commons.cli.CommandLine,org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>"
  ],
  "10.0.9": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.mapreduce.ContentOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.ContentReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.BinaryWriter: void write(com.marklogic.mapreduce.DocumentURI,org.apache.hadoop.io.BytesWritable)>",
    "<com.marklogic.mapreduce.test.ElementAttributeValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.CustomQuery: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.mapreduce.test.ValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.BinaryLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.WordsTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.FCheck: void checkTreeIndex(java.io.File)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElemValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.RevisionGrouper: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.KeyValueOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTreeJSON: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getOutputContentSource(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.MarkLogicOutputFormat: com.marklogic.mapreduce.utilities.TextArrayWritable getHosts(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.Command: void applyModuleConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.ContentOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getForestStatusMap(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.test.ElemAttrValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.HelloWorld: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: int run(java.lang.String[])>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.PropertyOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.BinaryReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.ContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>",
    "<com.marklogic.mapreduce.test.ValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.LinkCountCooccurrences: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountHDFS: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCount: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInDoc: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountValue: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MultithreadedZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentWriter: com.marklogic.xcc.Content createContent(com.marklogic.mapreduce.DocumentURI,java.lang.Object)>",
    "<com.marklogic.mapreduce.examples.ZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInProperty: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.Command: boolean isStreaming(org.apache.commons.cli.CommandLine,org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.NodeOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>"
  ],
  "10.0.9.2": [
    "<com.marklogic.contentpump.TransformOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getMimetypesMap()>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.marklogic.contentpump.ContentPump: void logVersions()>",
    "<com.marklogic.contentpump.SequenceFileReader: void initReader(org.apache.hadoop.mapreduce.InputSplit)>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.MultithreadedMapper$SubMapRecordReader: boolean nextKeyValue()>",
    "<com.marklogic.contentpump.LocalJobRunner$Monitor: void run()>",
    "<com.marklogic.mapreduce.ContentOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.ContentReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.BinaryWriter: void write(com.marklogic.mapreduce.DocumentURI,org.apache.hadoop.io.BytesWritable)>",
    "<com.marklogic.mapreduce.test.ElementAttributeValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: java.lang.String getServerVersion(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileLargeBinaryCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getInputContentSource(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.ContentPump: int runCommand(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.CustomQuery: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.OutputArchive: void newOutputStream()>",
    "<com.marklogic.mapreduce.test.ValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.BinaryLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.WordsTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.FCheck: void checkTreeIndex(java.io.File)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileBytesCreator: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElemValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.RevisionGrouper: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.KeyValueOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTreeJSON: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.utilities.InternalUtilities: com.marklogic.xcc.ContentSource getOutputContentSource(org.apache.hadoop.conf.Configuration,java.lang.String)>",
    "<com.marklogic.contentpump.InputType$6: void applyConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.MarkLogicOutputFormat: com.marklogic.mapreduce.utilities.TextArrayWritable getHosts(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.Command: void applyModuleConfigOptions(org.apache.hadoop.conf.Configuration,org.apache.commons.cli.CommandLine)>",
    "<com.marklogic.mapreduce.ContentOutputFormat: com.marklogic.mapreduce.LinkedMapWritable getForestStatusMap(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.contentpump.DocumentPathFilter: void setConf(org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.test.ElemAttrValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.HelloWorld: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MapTreeReduceTree: int run(java.lang.String[])>",
    "<com.marklogic.contentpump.examples.SimpleSequenceFileReader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.RDFInputFormat: com.marklogic.mapreduce.LinkedMapWritable getRoleMap(org.apache.hadoop.mapreduce.TaskAttemptContext)>",
    "<com.marklogic.mapreduce.PropertyOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.BinaryReader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.ContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.SingleDocumentWriter: void write(com.marklogic.mapreduce.DocumentURI,com.marklogic.mapreduce.MarkLogicDocument)>",
    "<com.marklogic.mapreduce.test.ValuesTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.DelimitedTextInputFormat: java.util.List getSplits(org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.contentpump.test.SimpleSequenceFileCompressCreator: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.TransformOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>",
    "<com.marklogic.mapreduce.examples.LinkCountCooccurrences: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountHDFS: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCount: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInDoc: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountValue: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.MultithreadedZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.ContentWriter: com.marklogic.xcc.Content createContent(com.marklogic.mapreduce.DocumentURI,java.lang.Object)>",
    "<com.marklogic.mapreduce.examples.ZipContentLoader: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.examples.LinkCountInProperty: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ValueCooccurrencesTest: void main(java.lang.String[])>",
    "<com.marklogic.mapreduce.test.ElementValueMatchTest: void main(java.lang.String[])>",
    "<com.marklogic.contentpump.Command: boolean isStreaming(org.apache.commons.cli.CommandLine,org.apache.hadoop.conf.Configuration)>",
    "<com.marklogic.mapreduce.NodeOutputFormat: void checkOutputSpecs(org.apache.hadoop.conf.Configuration,com.marklogic.xcc.ContentSource,org.apache.hadoop.mapreduce.JobContext)>"
  ]
}