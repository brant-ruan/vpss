{
  "blink-3.6.8": [
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: org.apache.hadoop.hive.metastore.api.Table createHiveTable(org.apache.flink.table.catalog.ObjectPath,org.apache.flink.table.catalog.CatalogTable)>",
    "<org.apache.flink.table.catalog.hive.HMSClientFactory: org.apache.flink.table.catalog.hive.HiveMetastoreClientWrapper create(java.lang.String)>",
    "<org.apache.flink.table.api.functions.hive.HiveGenericUDF: void openInternal()>",
    "<org.apache.flink.table.catalog.hive.HiveShimV234: org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer analyze(java.lang.String,org.apache.hadoop.hive.conf.HiveConf)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableUtil: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: java.util.List createHiveColumns(org.apache.flink.table.api.TableSchema)>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: org.apache.hadoop.hive.conf.HiveConf createHiveConf(java.lang.String)>",
    "<org.apache.flink.table.api.functions.hive.HiveSimpleUDF: java.lang.Object evalInternal(java.lang.Object[])>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat: org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat$HivePartitionWriter writerForLocation(java.lang.String)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat: void loadPartition(org.apache.hadoop.fs.Path,org.apache.hadoop.hive.metastore.api.Table,java.util.Map,org.apache.flink.table.catalog.hive.HiveMetastoreClientWrapper)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableFactory$HiveTableInfo: org.apache.flink.streaming.connectors.hive.HiveTableFactory$HiveTableInfo build()>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat: void open(int,int)>",
    "<org.apache.flink.table.api.functions.hive.HiveSimpleUDF: void openInternal()>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: void <clinit>()>",
    "<org.apache.flink.table.catalog.hive.HiveAnalyzer: void <init>(org.apache.hadoop.hive.conf.HiveConf)>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogGenericMetadataUtil: org.apache.hadoop.hive.metastore.api.Table createHiveTable(org.apache.flink.table.catalog.ObjectPath,org.apache.flink.table.catalog.CatalogTable)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableSink: org.apache.flink.streaming.api.datastream.DataStreamSink emitBoundedStream(org.apache.flink.streaming.api.datastream.DataStream,org.apache.flink.table.api.TableConfig,org.apache.flink.api.common.ExecutionConfig)>",
    "<org.apache.flink.table.catalog.hive.HiveShimV122: org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer analyze(java.lang.String,org.apache.hadoop.hive.conf.HiveConf)>"
  ],
  "blink-3.7.0": [
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: org.apache.hadoop.hive.metastore.api.Table createHiveTable(org.apache.flink.table.catalog.ObjectPath,org.apache.flink.table.catalog.CatalogTable)>",
    "<org.apache.flink.table.catalog.hive.HMSClientFactory: org.apache.flink.table.catalog.hive.HiveMetastoreClientWrapper create(java.lang.String)>",
    "<org.apache.flink.table.api.functions.hive.HiveGenericUDF: void openInternal()>",
    "<org.apache.flink.table.catalog.hive.HiveShimV234: org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer analyze(java.lang.String,org.apache.hadoop.hive.conf.HiveConf)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableUtil: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: java.util.List createHiveColumns(org.apache.flink.table.api.TableSchema)>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: org.apache.hadoop.hive.conf.HiveConf createHiveConf(java.lang.String)>",
    "<org.apache.flink.table.api.functions.hive.HiveSimpleUDF: java.lang.Object evalInternal(java.lang.Object[])>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat: org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat$HivePartitionWriter writerForLocation(java.lang.String)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat: void loadPartition(org.apache.hadoop.fs.Path,org.apache.hadoop.hive.metastore.api.Table,java.util.Map,org.apache.flink.table.catalog.hive.HiveMetastoreClientWrapper)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableFactory$HiveTableInfo: org.apache.flink.streaming.connectors.hive.HiveTableFactory$HiveTableInfo build()>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat: void open(int,int)>",
    "<org.apache.flink.table.api.functions.hive.HiveSimpleUDF: void openInternal()>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: void <clinit>()>",
    "<org.apache.flink.table.catalog.hive.HiveAnalyzer: void <init>(org.apache.hadoop.hive.conf.HiveConf)>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogGenericMetadataUtil: org.apache.hadoop.hive.metastore.api.Table createHiveTable(org.apache.flink.table.catalog.ObjectPath,org.apache.flink.table.catalog.CatalogTable)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableSink: org.apache.flink.streaming.api.datastream.DataStreamSink emitBoundedStream(org.apache.flink.streaming.api.datastream.DataStream,org.apache.flink.table.api.TableConfig,org.apache.flink.api.common.ExecutionConfig)>",
    "<org.apache.flink.table.catalog.hive.HiveShimV122: org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer analyze(java.lang.String,org.apache.hadoop.hive.conf.HiveConf)>"
  ],
  "blink-3.3.0": [
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: org.apache.hadoop.hive.metastore.api.Table createHiveTable(org.apache.flink.table.catalog.ObjectPath,org.apache.flink.table.catalog.CatalogTable)>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: org.apache.hadoop.hive.conf.HiveConf createHiveConf(java.lang.String)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableFactory$HiveTableInfo: org.apache.flink.streaming.connectors.hive.HiveTableFactory$HiveTableInfo build()>",
    "<org.apache.flink.table.catalog.hive.HiveAnalyzer: void <init>(org.apache.hadoop.hive.conf.HiveConf)>",
    "<org.apache.flink.table.catalog.hive.HMSClientFactory: org.apache.flink.table.catalog.hive.HiveMetastoreClientWrapper create(java.lang.String)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat: org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat$HivePartitionWriter writerForLocation(java.lang.String)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat: void loadPartition(org.apache.hadoop.fs.Path,org.apache.hadoop.hive.metastore.api.Table,java.util.Map,org.apache.flink.table.catalog.hive.HiveMetastoreClientWrapper)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat: void open(int,int)>",
    "<org.apache.flink.table.catalog.hive.HiveShimV122: org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer analyze(java.lang.String,org.apache.hadoop.hive.conf.HiveConf)>",
    "<org.apache.flink.table.api.functions.hive.HiveSimpleUDF: void openInternal()>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableUtil: org.apache.hadoop.hive.metastore.api.StorageDescriptor createStorageDescriptor(org.apache.hadoop.mapred.JobConf,org.apache.flink.api.java.typeutils.RowTypeInfo)>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogGenericMetadataUtil: org.apache.hadoop.hive.metastore.api.Table createHiveTable(org.apache.flink.table.catalog.ObjectPath,org.apache.flink.table.catalog.CatalogTable)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableSink: org.apache.flink.streaming.api.datastream.DataStreamSink emitBoundedStream(org.apache.flink.streaming.api.datastream.DataStream,org.apache.flink.table.api.TableConfig,org.apache.flink.api.common.ExecutionConfig)>",
    "<org.apache.flink.table.catalog.hive.HiveShimV234: org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer analyze(java.lang.String,org.apache.hadoop.hive.conf.HiveConf)>",
    "<org.apache.flink.table.api.functions.hive.HiveGenericUDF: void openInternal()>",
    "<org.apache.flink.table.api.functions.hive.HiveSimpleUDF: java.lang.Object evalInternal(java.lang.Object[])>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableUtil: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: void <clinit>()>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: java.util.List createHiveColumns(org.apache.flink.table.api.TableSchema)>"
  ],
  "blink-3.4.0": [
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: org.apache.hadoop.hive.metastore.api.Table createHiveTable(org.apache.flink.table.catalog.ObjectPath,org.apache.flink.table.catalog.CatalogTable)>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: org.apache.hadoop.hive.conf.HiveConf createHiveConf(java.lang.String)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableFactory$HiveTableInfo: org.apache.flink.streaming.connectors.hive.HiveTableFactory$HiveTableInfo build()>",
    "<org.apache.flink.table.catalog.hive.HiveAnalyzer: void <init>(org.apache.hadoop.hive.conf.HiveConf)>",
    "<org.apache.flink.table.catalog.hive.HMSClientFactory: org.apache.flink.table.catalog.hive.HiveMetastoreClientWrapper create(java.lang.String)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat: org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat$HivePartitionWriter writerForLocation(java.lang.String)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat: void loadPartition(org.apache.hadoop.fs.Path,org.apache.hadoop.hive.metastore.api.Table,java.util.Map,org.apache.flink.table.catalog.hive.HiveMetastoreClientWrapper)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableOutputFormat: void open(int,int)>",
    "<org.apache.flink.table.catalog.hive.HiveShimV122: org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer analyze(java.lang.String,org.apache.hadoop.hive.conf.HiveConf)>",
    "<org.apache.flink.table.api.functions.hive.HiveSimpleUDF: void openInternal()>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableUtil: org.apache.hadoop.hive.metastore.api.StorageDescriptor createStorageDescriptor(org.apache.hadoop.mapred.JobConf,org.apache.flink.api.java.typeutils.RowTypeInfo)>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogGenericMetadataUtil: org.apache.hadoop.hive.metastore.api.Table createHiveTable(org.apache.flink.table.catalog.ObjectPath,org.apache.flink.table.catalog.CatalogTable)>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableSink: org.apache.flink.streaming.api.datastream.DataStreamSink emitBoundedStream(org.apache.flink.streaming.api.datastream.DataStream,org.apache.flink.table.api.TableConfig,org.apache.flink.api.common.ExecutionConfig)>",
    "<org.apache.flink.table.catalog.hive.HiveShimV234: org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer analyze(java.lang.String,org.apache.hadoop.hive.conf.HiveConf)>",
    "<org.apache.flink.table.api.functions.hive.HiveGenericUDF: void openInternal()>",
    "<org.apache.flink.table.api.functions.hive.HiveSimpleUDF: java.lang.Object evalInternal(java.lang.Object[])>",
    "<org.apache.flink.streaming.connectors.hive.HiveTableUtil: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector getObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: void <clinit>()>",
    "<org.apache.flink.table.catalog.hive.HiveCatalogUtil: java.util.List createHiveColumns(org.apache.flink.table.api.TableSchema)>"
  ]
}