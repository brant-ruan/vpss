{
  "2.0.0": [
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void decodeBatch(org.apache.hadoop.hive.ql.io.orc.encoded.Reader$OrcEncodedColumnBatch,org.apache.hadoop.hive.ql.io.orc.encoded.Consumer)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.hive.llap.cache.Cache,org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.ql.io.sarg.SearchArgument,java.lang.String[],org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters)>",
    "<org.apache.hadoop.hive.llap.security.LlapSecurityHelper: org.apache.hadoop.security.UserGroupInformation loginWithKerberos(java.lang.String,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat$LlapRecordReader: void <init>(org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.FileSplit,java.util.List,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: boolean determineRgsToRead(boolean[],int,java.util.ArrayList)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureOrcReader()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenResponseProto getDelegationToken(com.google.protobuf.RpcController,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenRequestProto)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.security.LlapSecurityHelper: org.apache.hadoop.security.token.Token getDelegationToken()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void run(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: java.util.List getRegisteredFragments()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: java.lang.Long determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: java.lang.Void performDataRead()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable: org.apache.tez.runtime.task.TaskRunner2Result callInternal()>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: void <init>(long,org.apache.hadoop.hive.ql.io.orc.Reader)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void main(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol getUmbilical()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle: org.jboss.netty.channel.ChannelFuture sendMapOutput(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.Channel,java.lang.String,java.lang.String,int,org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle$MapOutputInfo)>"
  ],
  "2.1.1": [
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void decodeBatch(org.apache.hadoop.hive.ql.io.orc.encoded.Reader$OrcEncodedColumnBatch,org.apache.hadoop.hive.ql.io.orc.encoded.Consumer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo getTokenInfo(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: boolean isPermissiveManagementAcl(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl$TokenRequiresSigning getSigningConfig(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat$LlapRecordReader: void <init>(org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.FileSplit,java.util.List,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureOrcReader()>",
    "<org.apache.hadoop.hive.llap.cache.LowLevelLrfuCachePolicy: void <init>(int,long,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cache.LowLevelLrfuCachePolicy: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void populateConfWithLlapProperties(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.StaticPermanentFunctionChecker: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.security.LlapSignerImpl: org.apache.hadoop.hive.llap.security.LlapSigner$SignedMessage serializeAndSign(org.apache.hadoop.hive.llap.security.LlapSigner$Signable)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void outputJson(java.io.PrintWriter)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: void <init>(java.lang.Object,org.apache.hadoop.hive.ql.io.orc.Reader)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.cache.LowLevelCacheMemoryManager: void <init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.cache.LowLevelCachePolicy,org.apache.hadoop.hive.llap.metrics.LlapDaemonCacheMetrics)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: int run(org.apache.hadoop.hive.llap.cli.LlapStatusOptionsProcessor$LlapStatusOptions)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable: org.apache.tez.runtime.task.TaskRunner2Result callInternal()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: java.util.Set downloadPermanentFunctions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hive.llap.configuration.LlapDaemonConfiguration: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void <init>(org.apache.hadoop.conf.Configuration,int,long,boolean,boolean,long,java.lang.String[],int,int,int,int,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[],java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void refreshClassloader()>",
    "<org.apache.hadoop.hive.llap.cache.SimpleAllocator: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat$LlapRecordReader: boolean init()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void init()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server createServer(java.lang.Class,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,int,com.google.protobuf.BlockingService,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: void checkPermissions(java.lang.String,java.lang.String,java.lang.String,java.lang.Object)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle: org.jboss.netty.channel.ChannelFuture sendMapOutput(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.Channel,java.lang.String,java.lang.String,int,org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle$MapOutputInfo)>",
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: org.apache.orc.TypeDescription getFileSchema()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.ql.io.sarg.SearchArgument,java.lang.String[],org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void initializeLogging(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapIoImpl: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureMetadataReader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: org.apache.hadoop.hive.llap.daemon.impl.QueryFragmentInfo registerFragment(org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,java.lang.String,java.lang.String,int,java.lang.String,int,int,java.lang.String,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: boolean determineRgsToRead(boolean[],int,java.util.ArrayList)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices: void serviceInit(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void copyConfig(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenResponseProto getDelegationToken(com.google.protobuf.RpcController,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenRequestProto)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void startLocalizeAllFunctions()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void run(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void validateFileMetadata()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: java.util.List getRegisteredFragments()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$ExitCode populateAppStatusFromLlapRegistry(java.lang.String,org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$AppStatusBuilder)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void <init>(java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.hive.llap.daemon.QueryFailedHandler,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.counters.QueryFragmentCounters: void <init>(org.apache.hadoop.conf.Configuration,org.apache.tez.common.counters.TezCounters)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: long getMaxTotalMemorySize(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void main(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl$LlapExecutionContext: void initializeHook(org.apache.hadoop.hive.ql.exec.tez.TezProcessor)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol getUmbilical()>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: void <init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.cache.MemoryManager,org.apache.hadoop.hive.llap.metrics.LlapDaemonCacheMetrics)>",
    "<org.apache.hadoop.hive.llap.io.decode.OrcColumnVectorProducer: void <init>(org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.metrics.LlapDaemonCacheMetrics,org.apache.hadoop.hive.llap.metrics.LlapDaemonIOMetrics)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void <init>(org.apache.hadoop.conf.Configuration,int,int,boolean,java.lang.String[],java.util.concurrent.atomic.AtomicReference,java.util.concurrent.atomic.AtomicReference,long,org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorMetrics,org.apache.hadoop.hive.llap.daemon.impl.AMReporter,java.lang.ClassLoader,org.apache.hadoop.hive.llap.DaemonId)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices$LlapPeerRegistryServlet: void doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>"
  ],
  "2.3.10": [
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo getTokenInfo(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription,java.util.Map)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void logSecurityErrorRarely(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: org.apache.hadoop.hive.llap.daemon.impl.QueryFragmentInfo registerFragment(org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,int,int,java.lang.String,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo,org.apache.hadoop.hive.llap.LlapNodeId)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable: org.apache.tez.runtime.task.TaskRunner2Result callInternal()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[],java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void <init>(org.apache.hadoop.conf.Configuration,int,long,boolean,boolean,long,java.lang.String[],int,int,int,int,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: void checkPermissions(java.lang.String,java.lang.String,java.lang.String,java.lang.Object)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle: org.jboss.netty.channel.ChannelFuture sendMapOutput(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.Channel,java.lang.String,java.lang.String,int,org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle$MapOutputInfo)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: int run(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void <init>(org.apache.hadoop.conf.Configuration,int,int,boolean,java.lang.String[],java.util.concurrent.atomic.AtomicReference,java.util.concurrent.atomic.AtomicReference,long,org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorMetrics,org.apache.hadoop.hive.llap.daemon.impl.AMReporter,java.lang.ClassLoader,org.apache.hadoop.hive.llap.DaemonId,org.apache.hadoop.hive.common.UgiFactory,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices: void serviceInit(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: void setupUmbilicalUgi(java.lang.String,org.apache.hadoop.security.token.Token,java.lang.String,int)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenResponseProto getDelegationToken(com.google.protobuf.RpcController,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenRequestProto)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedChunkedFile: void close()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.ql.io.sarg.SearchArgument,java.lang.String[],org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server startProtocolServer(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.conf.Configuration,com.google.protobuf.BlockingService,java.lang.Class,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedFileRegion: void transferSuccessful()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void main(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol getUmbilical()>"
  ],
  "2.3.4": [
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void decodeBatch(org.apache.hadoop.hive.ql.io.orc.encoded.Reader$OrcEncodedColumnBatch,org.apache.hadoop.hive.ql.io.orc.encoded.Consumer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkResponseProto submitWork(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo getTokenInfo(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl$TokenRequiresSigning getSigningConfig(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void populateConfWithLlapProperties(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.StaticPermanentFunctionChecker: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter create(org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,java.util.Map,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: void <init>(java.lang.Object,org.apache.hadoop.hive.ql.io.orc.Reader)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver$4: java.lang.Void call()>",
    "<org.apache.hadoop.hive.llap.cli.LlapSliderUtils: java.io.File startSetSliderLibDir()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void refreshClassloader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void init()>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: void <init>(org.apache.hadoop.hive.ql.plan.MapWork,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.FileSplit,java.util.List,java.lang.String,org.apache.hadoop.hive.llap.io.decode.ColumnVectorProducer,java.util.concurrent.ExecutorService,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server createServer(java.lang.Class,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,int,com.google.protobuf.BlockingService,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: void checkPermissions(java.lang.String,java.lang.String,java.lang.String,java.lang.Object)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle: org.jboss.netty.channel.ChannelFuture sendMapOutput(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.Channel,java.lang.String,java.lang.String,int,org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle$MapOutputInfo)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec extractVertexSpec(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: void setupUmbilicalUgi(java.lang.String,org.apache.hadoop.security.token.Token,java.lang.String,int)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenResponseProto getDelegationToken(com.google.protobuf.RpcController,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenRequestProto)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedChunkedFile: void close()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void startLocalizeAllFunctions()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters createSerdeParams(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void <init>(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.hive.llap.daemon.QueryFailedHandler,org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.DaemonId,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: org.codehaus.jettison.json.JSONObject createConfigJson(long,long,long,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory$KerberosUgiFactory: void <init>(java.lang.String,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server startProtocolServer(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.conf.Configuration,com.google.protobuf.BlockingService,java.lang.Class,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: org.apache.hadoop.hive.common.UgiFactory createFsUgiFactory(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.counters.QueryFragmentCounters: void <init>(org.apache.hadoop.conf.Configuration,org.apache.tez.common.counters.TezCounters)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: long getMaxTotalMemorySize(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter: org.apache.hadoop.hive.ql.io.orc.Writer createOrcWriter(org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector)>",
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void setFileMetadata(org.apache.hadoop.hive.llap.io.metadata.ConsumerFileMetadata)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: boolean isPermissiveManagementAcl(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: long determineXmxHeadroom(org.apache.hadoop.conf.Configuration,long,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter: void validateIncludes(org.apache.orc.OrcProto$Footer)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureOrcReader()>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: void <clinit>()>",
    "<org.apache.hadoop.hive.llap.cache.LowLevelLrfuCachePolicy: void <init>(int,long,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription,java.util.Map)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void logSecurityErrorRarely(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: org.apache.hadoop.hive.ql.plan.MapWork findMapWork(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void outputJson(java.io.PrintWriter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: org.apache.hadoop.hive.llap.daemon.impl.QueryFragmentInfo registerFragment(org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,int,int,java.lang.String,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo,org.apache.hadoop.hive.llap.LlapNodeId)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable: org.apache.tez.runtime.task.TaskRunner2Result callInternal()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: java.util.Set downloadPermanentFunctions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hive.llap.configuration.LlapDaemonConfiguration: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void <init>(org.apache.hadoop.conf.Configuration,int,long,boolean,boolean,long,java.lang.String[],int,int,int,int,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[],java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: org.apache.orc.TypeDescription getSchema()>",
    "<org.apache.hadoop.hive.llap.cache.SimpleAllocator: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.tez.runtime.api.impl.TezEvent extractInitialEvent(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.io.decode.GenericColumnVectorProducer$SerDeFileMetadata: void <init>(org.apache.hadoop.hive.serde2.Deserializer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void registerTask(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: int determineAllocSize(org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void initializeLogging(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: int run(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapIoImpl: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureMetadataReader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void <init>(org.apache.hadoop.conf.Configuration,int,int,boolean,java.lang.String[],java.util.concurrent.atomic.AtomicReference,java.util.concurrent.atomic.AtomicReference,long,org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorMetrics,org.apache.hadoop.hive.llap.daemon.impl.AMReporter,java.lang.ClassLoader,org.apache.hadoop.hive.llap.DaemonId,org.apache.hadoop.hive.common.UgiFactory,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices: void serviceInit(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: boolean determineRgsToRead(boolean[],int,java.util.ArrayList)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void copyConfig(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: int run(org.apache.hadoop.hive.llap.cli.LlapStatusOptionsProcessor$LlapStatusOptions,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void validateFileMetadata()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void taskKilled(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: java.util.List getRegisteredFragments()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.ql.io.sarg.SearchArgument,java.lang.String[],org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedFileRegion: void transferSuccessful()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void setupConf()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void main(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol getUmbilical()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$ExitCode populateAppStatusFromLlapRegistry(org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$AppStatusBuilder,long)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: void <init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.cache.MemoryManager,org.apache.hadoop.hive.llap.metrics.LlapDaemonCacheMetrics)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices$LlapPeerRegistryServlet: void doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void startReadSplitFromFile(org.apache.hadoop.mapred.FileSplit,boolean[],org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl$StripeData)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>"
  ],
  "2.3.0": [
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void decodeBatch(org.apache.hadoop.hive.ql.io.orc.encoded.Reader$OrcEncodedColumnBatch,org.apache.hadoop.hive.ql.io.orc.encoded.Consumer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkResponseProto submitWork(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo getTokenInfo(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl$TokenRequiresSigning getSigningConfig(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void populateConfWithLlapProperties(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.StaticPermanentFunctionChecker: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter create(org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,java.util.Map,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: void <init>(java.lang.Object,org.apache.hadoop.hive.ql.io.orc.Reader)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver$4: java.lang.Void call()>",
    "<org.apache.hadoop.hive.llap.cli.LlapSliderUtils: java.io.File startSetSliderLibDir()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void refreshClassloader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void init()>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: void <init>(org.apache.hadoop.hive.ql.plan.MapWork,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.FileSplit,java.util.List,java.lang.String,org.apache.hadoop.hive.llap.io.decode.ColumnVectorProducer,java.util.concurrent.ExecutorService,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server createServer(java.lang.Class,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,int,com.google.protobuf.BlockingService,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: void checkPermissions(java.lang.String,java.lang.String,java.lang.String,java.lang.Object)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle: org.jboss.netty.channel.ChannelFuture sendMapOutput(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.Channel,java.lang.String,java.lang.String,int,org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle$MapOutputInfo)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec extractVertexSpec(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: void setupUmbilicalUgi(java.lang.String,org.apache.hadoop.security.token.Token,java.lang.String,int)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenResponseProto getDelegationToken(com.google.protobuf.RpcController,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenRequestProto)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedChunkedFile: void close()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void startLocalizeAllFunctions()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters createSerdeParams(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void <init>(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.hive.llap.daemon.QueryFailedHandler,org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.DaemonId,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: org.codehaus.jettison.json.JSONObject createConfigJson(long,long,long,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory$KerberosUgiFactory: void <init>(java.lang.String,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server startProtocolServer(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.conf.Configuration,com.google.protobuf.BlockingService,java.lang.Class,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: org.apache.hadoop.hive.common.UgiFactory createFsUgiFactory(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.counters.QueryFragmentCounters: void <init>(org.apache.hadoop.conf.Configuration,org.apache.tez.common.counters.TezCounters)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: long getMaxTotalMemorySize(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter: org.apache.hadoop.hive.ql.io.orc.Writer createOrcWriter(org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector)>",
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void setFileMetadata(org.apache.hadoop.hive.llap.io.metadata.ConsumerFileMetadata)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: boolean isPermissiveManagementAcl(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: long determineXmxHeadroom(org.apache.hadoop.conf.Configuration,long,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter: void validateIncludes(org.apache.orc.OrcProto$Footer)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureOrcReader()>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: void <clinit>()>",
    "<org.apache.hadoop.hive.llap.cache.LowLevelLrfuCachePolicy: void <init>(int,long,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription,java.util.Map)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void logSecurityErrorRarely(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: org.apache.hadoop.hive.ql.plan.MapWork findMapWork(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void outputJson(java.io.PrintWriter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: org.apache.hadoop.hive.llap.daemon.impl.QueryFragmentInfo registerFragment(org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,int,int,java.lang.String,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo,org.apache.hadoop.hive.llap.LlapNodeId)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable: org.apache.tez.runtime.task.TaskRunner2Result callInternal()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: java.util.Set downloadPermanentFunctions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hive.llap.configuration.LlapDaemonConfiguration: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void <init>(org.apache.hadoop.conf.Configuration,int,long,boolean,boolean,long,java.lang.String[],int,int,int,int,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[],java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: org.apache.orc.TypeDescription getSchema()>",
    "<org.apache.hadoop.hive.llap.cache.SimpleAllocator: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.tez.runtime.api.impl.TezEvent extractInitialEvent(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.io.decode.GenericColumnVectorProducer$SerDeFileMetadata: void <init>(org.apache.hadoop.hive.serde2.Deserializer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void registerTask(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: int determineAllocSize(org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void initializeLogging(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: int run(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapIoImpl: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureMetadataReader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void <init>(org.apache.hadoop.conf.Configuration,int,int,boolean,java.lang.String[],java.util.concurrent.atomic.AtomicReference,java.util.concurrent.atomic.AtomicReference,long,org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorMetrics,org.apache.hadoop.hive.llap.daemon.impl.AMReporter,java.lang.ClassLoader,org.apache.hadoop.hive.llap.DaemonId,org.apache.hadoop.hive.common.UgiFactory,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices: void serviceInit(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: boolean determineRgsToRead(boolean[],int,java.util.ArrayList)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void copyConfig(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: int run(org.apache.hadoop.hive.llap.cli.LlapStatusOptionsProcessor$LlapStatusOptions,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void validateFileMetadata()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void taskKilled(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: java.util.List getRegisteredFragments()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.ql.io.sarg.SearchArgument,java.lang.String[],org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedFileRegion: void transferSuccessful()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void setupConf()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void main(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol getUmbilical()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$ExitCode populateAppStatusFromLlapRegistry(org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$AppStatusBuilder,long)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: void <init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.cache.MemoryManager,org.apache.hadoop.hive.llap.metrics.LlapDaemonCacheMetrics)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices$LlapPeerRegistryServlet: void doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void startReadSplitFromFile(org.apache.hadoop.mapred.FileSplit,boolean[],org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl$StripeData)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>"
  ],
  "2.0.1": [
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.hive.llap.cache.Cache,org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.ql.io.sarg.SearchArgument,java.lang.String[],org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo getTokenInfo(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.security.LlapSecurityHelper: org.apache.hadoop.security.UserGroupInformation loginWithKerberos(java.lang.String,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenResponseProto getDelegationToken(com.google.protobuf.RpcController,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenRequestProto)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.security.LlapSecurityHelper: org.apache.hadoop.security.token.Token getDelegationToken()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void run(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.security.LlapSignerImpl: org.apache.hadoop.hive.llap.security.LlapSigner$SignedMessage serializeAndSign(org.apache.hadoop.hive.llap.security.LlapSigner$Signable)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable: org.apache.tez.runtime.task.TaskRunner2Result callInternal()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void main(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol getUmbilical()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: void checkPermissions(java.lang.String,java.lang.String,java.lang.String,java.lang.Object)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle: org.jboss.netty.channel.ChannelFuture sendMapOutput(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.Channel,java.lang.String,java.lang.String,int,org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle$MapOutputInfo)>"
  ],
  "2.3.5": [
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void decodeBatch(org.apache.hadoop.hive.ql.io.orc.encoded.Reader$OrcEncodedColumnBatch,org.apache.hadoop.hive.ql.io.orc.encoded.Consumer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkResponseProto submitWork(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo getTokenInfo(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl$TokenRequiresSigning getSigningConfig(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void populateConfWithLlapProperties(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.StaticPermanentFunctionChecker: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter create(org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,java.util.Map,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: void <init>(java.lang.Object,org.apache.hadoop.hive.ql.io.orc.Reader)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver$4: java.lang.Void call()>",
    "<org.apache.hadoop.hive.llap.cli.LlapSliderUtils: java.io.File startSetSliderLibDir()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void refreshClassloader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void init()>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: void <init>(org.apache.hadoop.hive.ql.plan.MapWork,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.FileSplit,java.util.List,java.lang.String,org.apache.hadoop.hive.llap.io.decode.ColumnVectorProducer,java.util.concurrent.ExecutorService,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server createServer(java.lang.Class,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,int,com.google.protobuf.BlockingService,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: void checkPermissions(java.lang.String,java.lang.String,java.lang.String,java.lang.Object)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle: org.jboss.netty.channel.ChannelFuture sendMapOutput(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.Channel,java.lang.String,java.lang.String,int,org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle$MapOutputInfo)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec extractVertexSpec(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: void setupUmbilicalUgi(java.lang.String,org.apache.hadoop.security.token.Token,java.lang.String,int)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenResponseProto getDelegationToken(com.google.protobuf.RpcController,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenRequestProto)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedChunkedFile: void close()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void startLocalizeAllFunctions()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters createSerdeParams(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void <init>(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.hive.llap.daemon.QueryFailedHandler,org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.DaemonId,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: org.codehaus.jettison.json.JSONObject createConfigJson(long,long,long,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory$KerberosUgiFactory: void <init>(java.lang.String,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server startProtocolServer(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.conf.Configuration,com.google.protobuf.BlockingService,java.lang.Class,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: org.apache.hadoop.hive.common.UgiFactory createFsUgiFactory(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.counters.QueryFragmentCounters: void <init>(org.apache.hadoop.conf.Configuration,org.apache.tez.common.counters.TezCounters)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: long getMaxTotalMemorySize(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter: org.apache.hadoop.hive.ql.io.orc.Writer createOrcWriter(org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector)>",
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void setFileMetadata(org.apache.hadoop.hive.llap.io.metadata.ConsumerFileMetadata)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: boolean isPermissiveManagementAcl(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: long determineXmxHeadroom(org.apache.hadoop.conf.Configuration,long,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter: void validateIncludes(org.apache.orc.OrcProto$Footer)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureOrcReader()>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: void <clinit>()>",
    "<org.apache.hadoop.hive.llap.cache.LowLevelLrfuCachePolicy: void <init>(int,long,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription,java.util.Map)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void logSecurityErrorRarely(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: org.apache.hadoop.hive.ql.plan.MapWork findMapWork(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void outputJson(java.io.PrintWriter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: org.apache.hadoop.hive.llap.daemon.impl.QueryFragmentInfo registerFragment(org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,int,int,java.lang.String,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo,org.apache.hadoop.hive.llap.LlapNodeId)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable: org.apache.tez.runtime.task.TaskRunner2Result callInternal()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: java.util.Set downloadPermanentFunctions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hive.llap.configuration.LlapDaemonConfiguration: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void <init>(org.apache.hadoop.conf.Configuration,int,long,boolean,boolean,long,java.lang.String[],int,int,int,int,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[],java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: org.apache.orc.TypeDescription getSchema()>",
    "<org.apache.hadoop.hive.llap.cache.SimpleAllocator: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.tez.runtime.api.impl.TezEvent extractInitialEvent(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.io.decode.GenericColumnVectorProducer$SerDeFileMetadata: void <init>(org.apache.hadoop.hive.serde2.Deserializer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void registerTask(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: int determineAllocSize(org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void initializeLogging(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: int run(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapIoImpl: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureMetadataReader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void <init>(org.apache.hadoop.conf.Configuration,int,int,boolean,java.lang.String[],java.util.concurrent.atomic.AtomicReference,java.util.concurrent.atomic.AtomicReference,long,org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorMetrics,org.apache.hadoop.hive.llap.daemon.impl.AMReporter,java.lang.ClassLoader,org.apache.hadoop.hive.llap.DaemonId,org.apache.hadoop.hive.common.UgiFactory,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices: void serviceInit(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: boolean determineRgsToRead(boolean[],int,java.util.ArrayList)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void copyConfig(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: int run(org.apache.hadoop.hive.llap.cli.LlapStatusOptionsProcessor$LlapStatusOptions,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void validateFileMetadata()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void taskKilled(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: java.util.List getRegisteredFragments()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.ql.io.sarg.SearchArgument,java.lang.String[],org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedFileRegion: void transferSuccessful()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void setupConf()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void main(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol getUmbilical()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$ExitCode populateAppStatusFromLlapRegistry(org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$AppStatusBuilder,long)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: void <init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.cache.MemoryManager,org.apache.hadoop.hive.llap.metrics.LlapDaemonCacheMetrics)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices$LlapPeerRegistryServlet: void doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void startReadSplitFromFile(org.apache.hadoop.mapred.FileSplit,boolean[],org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl$StripeData)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>"
  ],
  "3.0.0": [
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata getFileFooterFromCacheOrDisk()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: org.apache.orc.OrcProto$StripeFooter getStripeFooterFromCacheOrDisk(org.apache.orc.StripeInformation,org.apache.hadoop.hive.ql.io.orc.encoded.OrcBatchKey)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureCodecFromFileMetadata()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureRawDataReader(boolean)>",
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void setFileMetadata(org.apache.hadoop.hive.llap.io.metadata.ConsumerFileMetadata)>"
  ],
  "2.3.6": [
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void decodeBatch(org.apache.hadoop.hive.ql.io.orc.encoded.Reader$OrcEncodedColumnBatch,org.apache.hadoop.hive.ql.io.orc.encoded.Consumer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkResponseProto submitWork(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo getTokenInfo(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl$TokenRequiresSigning getSigningConfig(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void populateConfWithLlapProperties(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.StaticPermanentFunctionChecker: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter create(org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,java.util.Map,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: void <init>(java.lang.Object,org.apache.hadoop.hive.ql.io.orc.Reader)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver$4: java.lang.Void call()>",
    "<org.apache.hadoop.hive.llap.cli.LlapSliderUtils: java.io.File startSetSliderLibDir()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void init()>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: void <init>(org.apache.hadoop.hive.ql.plan.MapWork,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.FileSplit,java.util.List,java.lang.String,org.apache.hadoop.hive.llap.io.decode.ColumnVectorProducer,java.util.concurrent.ExecutorService,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server createServer(java.lang.Class,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,int,com.google.protobuf.BlockingService,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: void checkPermissions(java.lang.String,java.lang.String,java.lang.String,java.lang.Object)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle: org.jboss.netty.channel.ChannelFuture sendMapOutput(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.Channel,java.lang.String,java.lang.String,int,org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle$MapOutputInfo)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec extractVertexSpec(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: void setupUmbilicalUgi(java.lang.String,org.apache.hadoop.security.token.Token,java.lang.String,int)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenResponseProto getDelegationToken(com.google.protobuf.RpcController,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenRequestProto)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedChunkedFile: void close()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void startLocalizeAllFunctions()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters createSerdeParams(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void <init>(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.hive.llap.daemon.QueryFailedHandler,org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.DaemonId,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: org.codehaus.jettison.json.JSONObject createConfigJson(long,long,long,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory$KerberosUgiFactory: void <init>(java.lang.String,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server startProtocolServer(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.conf.Configuration,com.google.protobuf.BlockingService,java.lang.Class,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: org.apache.hadoop.hive.common.UgiFactory createFsUgiFactory(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.counters.QueryFragmentCounters: void <init>(org.apache.hadoop.conf.Configuration,org.apache.tez.common.counters.TezCounters)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: long getMaxTotalMemorySize(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter: org.apache.hadoop.hive.ql.io.orc.Writer createOrcWriter(org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector)>",
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void setFileMetadata(org.apache.hadoop.hive.llap.io.metadata.ConsumerFileMetadata)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: boolean isPermissiveManagementAcl(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: long determineXmxHeadroom(org.apache.hadoop.conf.Configuration,long,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter: void validateIncludes(org.apache.orc.OrcProto$Footer)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureOrcReader()>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: void <clinit>()>",
    "<org.apache.hadoop.hive.llap.cache.LowLevelLrfuCachePolicy: void <init>(int,long,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription,java.util.Map)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void logSecurityErrorRarely(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: org.apache.hadoop.hive.ql.plan.MapWork findMapWork(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void outputJson(java.io.PrintWriter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: org.apache.hadoop.hive.llap.daemon.impl.QueryFragmentInfo registerFragment(org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,int,int,java.lang.String,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo,org.apache.hadoop.hive.llap.LlapNodeId)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable: org.apache.tez.runtime.task.TaskRunner2Result callInternal()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: java.util.Set downloadPermanentFunctions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hive.llap.configuration.LlapDaemonConfiguration: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void <init>(org.apache.hadoop.conf.Configuration,int,long,boolean,boolean,long,java.lang.String[],int,int,int,int,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[],java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: org.apache.orc.TypeDescription getSchema()>",
    "<org.apache.hadoop.hive.llap.cache.SimpleAllocator: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.tez.runtime.api.impl.TezEvent extractInitialEvent(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.io.decode.GenericColumnVectorProducer$SerDeFileMetadata: void <init>(org.apache.hadoop.hive.serde2.Deserializer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void registerTask(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: int determineAllocSize(org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void initializeLogging(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: int run(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapIoImpl: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureMetadataReader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void <init>(org.apache.hadoop.conf.Configuration,int,int,boolean,java.lang.String[],java.util.concurrent.atomic.AtomicReference,java.util.concurrent.atomic.AtomicReference,long,org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorMetrics,org.apache.hadoop.hive.llap.daemon.impl.AMReporter,java.lang.ClassLoader,org.apache.hadoop.hive.llap.DaemonId,org.apache.hadoop.hive.common.UgiFactory,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices: void serviceInit(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: boolean determineRgsToRead(boolean[],int,java.util.ArrayList)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void copyConfig(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: int run(org.apache.hadoop.hive.llap.cli.LlapStatusOptionsProcessor$LlapStatusOptions,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void validateFileMetadata()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void taskKilled(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: java.util.List getRegisteredFragments()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.ql.io.sarg.SearchArgument,java.lang.String[],org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedFileRegion: void transferSuccessful()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void setupConf()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void main(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol getUmbilical()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$ExitCode populateAppStatusFromLlapRegistry(org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$AppStatusBuilder,long)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: void <init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.cache.MemoryManager,org.apache.hadoop.hive.llap.metrics.LlapDaemonCacheMetrics)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices$LlapPeerRegistryServlet: void doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void startReadSplitFromFile(org.apache.hadoop.mapred.FileSplit,boolean[],org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl$StripeData)>"
  ],
  "2.3.1": [
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void decodeBatch(org.apache.hadoop.hive.ql.io.orc.encoded.Reader$OrcEncodedColumnBatch,org.apache.hadoop.hive.ql.io.orc.encoded.Consumer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkResponseProto submitWork(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo getTokenInfo(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl$TokenRequiresSigning getSigningConfig(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void populateConfWithLlapProperties(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.StaticPermanentFunctionChecker: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter create(org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,java.util.Map,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: void <init>(java.lang.Object,org.apache.hadoop.hive.ql.io.orc.Reader)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver$4: java.lang.Void call()>",
    "<org.apache.hadoop.hive.llap.cli.LlapSliderUtils: java.io.File startSetSliderLibDir()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void refreshClassloader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void init()>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: void <init>(org.apache.hadoop.hive.ql.plan.MapWork,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.FileSplit,java.util.List,java.lang.String,org.apache.hadoop.hive.llap.io.decode.ColumnVectorProducer,java.util.concurrent.ExecutorService,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server createServer(java.lang.Class,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,int,com.google.protobuf.BlockingService,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: void checkPermissions(java.lang.String,java.lang.String,java.lang.String,java.lang.Object)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle: org.jboss.netty.channel.ChannelFuture sendMapOutput(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.Channel,java.lang.String,java.lang.String,int,org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle$MapOutputInfo)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec extractVertexSpec(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: void setupUmbilicalUgi(java.lang.String,org.apache.hadoop.security.token.Token,java.lang.String,int)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenResponseProto getDelegationToken(com.google.protobuf.RpcController,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenRequestProto)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedChunkedFile: void close()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void startLocalizeAllFunctions()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters createSerdeParams(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void <init>(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.hive.llap.daemon.QueryFailedHandler,org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.DaemonId,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: org.codehaus.jettison.json.JSONObject createConfigJson(long,long,long,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory$KerberosUgiFactory: void <init>(java.lang.String,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server startProtocolServer(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.conf.Configuration,com.google.protobuf.BlockingService,java.lang.Class,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: org.apache.hadoop.hive.common.UgiFactory createFsUgiFactory(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.counters.QueryFragmentCounters: void <init>(org.apache.hadoop.conf.Configuration,org.apache.tez.common.counters.TezCounters)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: long getMaxTotalMemorySize(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter: org.apache.hadoop.hive.ql.io.orc.Writer createOrcWriter(org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector)>",
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void setFileMetadata(org.apache.hadoop.hive.llap.io.metadata.ConsumerFileMetadata)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: boolean isPermissiveManagementAcl(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: long determineXmxHeadroom(org.apache.hadoop.conf.Configuration,long,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter: void validateIncludes(org.apache.orc.OrcProto$Footer)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureOrcReader()>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: void <clinit>()>",
    "<org.apache.hadoop.hive.llap.cache.LowLevelLrfuCachePolicy: void <init>(int,long,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription,java.util.Map)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void logSecurityErrorRarely(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: org.apache.hadoop.hive.ql.plan.MapWork findMapWork(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void outputJson(java.io.PrintWriter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: org.apache.hadoop.hive.llap.daemon.impl.QueryFragmentInfo registerFragment(org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,int,int,java.lang.String,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo,org.apache.hadoop.hive.llap.LlapNodeId)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable: org.apache.tez.runtime.task.TaskRunner2Result callInternal()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: java.util.Set downloadPermanentFunctions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hive.llap.configuration.LlapDaemonConfiguration: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void <init>(org.apache.hadoop.conf.Configuration,int,long,boolean,boolean,long,java.lang.String[],int,int,int,int,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[],java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: org.apache.orc.TypeDescription getSchema()>",
    "<org.apache.hadoop.hive.llap.cache.SimpleAllocator: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.tez.runtime.api.impl.TezEvent extractInitialEvent(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.io.decode.GenericColumnVectorProducer$SerDeFileMetadata: void <init>(org.apache.hadoop.hive.serde2.Deserializer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void registerTask(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: int determineAllocSize(org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void initializeLogging(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: int run(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapIoImpl: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureMetadataReader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void <init>(org.apache.hadoop.conf.Configuration,int,int,boolean,java.lang.String[],java.util.concurrent.atomic.AtomicReference,java.util.concurrent.atomic.AtomicReference,long,org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorMetrics,org.apache.hadoop.hive.llap.daemon.impl.AMReporter,java.lang.ClassLoader,org.apache.hadoop.hive.llap.DaemonId,org.apache.hadoop.hive.common.UgiFactory,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices: void serviceInit(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: boolean determineRgsToRead(boolean[],int,java.util.ArrayList)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void copyConfig(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: int run(org.apache.hadoop.hive.llap.cli.LlapStatusOptionsProcessor$LlapStatusOptions,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void validateFileMetadata()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void taskKilled(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: java.util.List getRegisteredFragments()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.ql.io.sarg.SearchArgument,java.lang.String[],org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedFileRegion: void transferSuccessful()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void setupConf()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void main(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol getUmbilical()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$ExitCode populateAppStatusFromLlapRegistry(org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$AppStatusBuilder,long)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: void <init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.cache.MemoryManager,org.apache.hadoop.hive.llap.metrics.LlapDaemonCacheMetrics)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices$LlapPeerRegistryServlet: void doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void startReadSplitFromFile(org.apache.hadoop.mapred.FileSplit,boolean[],org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl$StripeData)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>"
  ],
  "2.3.8": [
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo getTokenInfo(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription,java.util.Map)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void logSecurityErrorRarely(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: org.apache.hadoop.hive.llap.daemon.impl.QueryFragmentInfo registerFragment(org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,int,int,java.lang.String,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo,org.apache.hadoop.hive.llap.LlapNodeId)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable: org.apache.tez.runtime.task.TaskRunner2Result callInternal()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[],java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void <init>(org.apache.hadoop.conf.Configuration,int,long,boolean,boolean,long,java.lang.String[],int,int,int,int,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: void checkPermissions(java.lang.String,java.lang.String,java.lang.String,java.lang.Object)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle: org.jboss.netty.channel.ChannelFuture sendMapOutput(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.Channel,java.lang.String,java.lang.String,int,org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle$MapOutputInfo)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: int run(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void <init>(org.apache.hadoop.conf.Configuration,int,int,boolean,java.lang.String[],java.util.concurrent.atomic.AtomicReference,java.util.concurrent.atomic.AtomicReference,long,org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorMetrics,org.apache.hadoop.hive.llap.daemon.impl.AMReporter,java.lang.ClassLoader,org.apache.hadoop.hive.llap.DaemonId,org.apache.hadoop.hive.common.UgiFactory,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices: void serviceInit(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: void setupUmbilicalUgi(java.lang.String,org.apache.hadoop.security.token.Token,java.lang.String,int)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenResponseProto getDelegationToken(com.google.protobuf.RpcController,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenRequestProto)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedChunkedFile: void close()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.ql.io.sarg.SearchArgument,java.lang.String[],org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server startProtocolServer(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.conf.Configuration,com.google.protobuf.BlockingService,java.lang.Class,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedFileRegion: void transferSuccessful()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void main(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol getUmbilical()>"
  ],
  "2.3.9": [
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo getTokenInfo(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription,java.util.Map)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void logSecurityErrorRarely(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: org.apache.hadoop.hive.llap.daemon.impl.QueryFragmentInfo registerFragment(org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,int,int,java.lang.String,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo,org.apache.hadoop.hive.llap.LlapNodeId)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable: org.apache.tez.runtime.task.TaskRunner2Result callInternal()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[],java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void <init>(org.apache.hadoop.conf.Configuration,int,long,boolean,boolean,long,java.lang.String[],int,int,int,int,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: void checkPermissions(java.lang.String,java.lang.String,java.lang.String,java.lang.Object)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle: org.jboss.netty.channel.ChannelFuture sendMapOutput(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.Channel,java.lang.String,java.lang.String,int,org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle$MapOutputInfo)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: int run(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void <init>(org.apache.hadoop.conf.Configuration,int,int,boolean,java.lang.String[],java.util.concurrent.atomic.AtomicReference,java.util.concurrent.atomic.AtomicReference,long,org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorMetrics,org.apache.hadoop.hive.llap.daemon.impl.AMReporter,java.lang.ClassLoader,org.apache.hadoop.hive.llap.DaemonId,org.apache.hadoop.hive.common.UgiFactory,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices: void serviceInit(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: void setupUmbilicalUgi(java.lang.String,org.apache.hadoop.security.token.Token,java.lang.String,int)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenResponseProto getDelegationToken(com.google.protobuf.RpcController,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenRequestProto)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedChunkedFile: void close()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.ql.io.sarg.SearchArgument,java.lang.String[],org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server startProtocolServer(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.conf.Configuration,com.google.protobuf.BlockingService,java.lang.Class,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedFileRegion: void transferSuccessful()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void main(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol getUmbilical()>"
  ],
  "2.3.3": [
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void decodeBatch(org.apache.hadoop.hive.ql.io.orc.encoded.Reader$OrcEncodedColumnBatch,org.apache.hadoop.hive.ql.io.orc.encoded.Consumer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkResponseProto submitWork(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo getTokenInfo(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl$TokenRequiresSigning getSigningConfig(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void populateConfWithLlapProperties(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.StaticPermanentFunctionChecker: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter create(org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,java.util.Map,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: void <init>(java.lang.Object,org.apache.hadoop.hive.ql.io.orc.Reader)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver$4: java.lang.Void call()>",
    "<org.apache.hadoop.hive.llap.cli.LlapSliderUtils: java.io.File startSetSliderLibDir()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void refreshClassloader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void init()>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: void <init>(org.apache.hadoop.hive.ql.plan.MapWork,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.FileSplit,java.util.List,java.lang.String,org.apache.hadoop.hive.llap.io.decode.ColumnVectorProducer,java.util.concurrent.ExecutorService,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server createServer(java.lang.Class,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,int,com.google.protobuf.BlockingService,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: void checkPermissions(java.lang.String,java.lang.String,java.lang.String,java.lang.Object)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle: org.jboss.netty.channel.ChannelFuture sendMapOutput(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.Channel,java.lang.String,java.lang.String,int,org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle$MapOutputInfo)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec extractVertexSpec(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: void setupUmbilicalUgi(java.lang.String,org.apache.hadoop.security.token.Token,java.lang.String,int)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenResponseProto getDelegationToken(com.google.protobuf.RpcController,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenRequestProto)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedChunkedFile: void close()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void startLocalizeAllFunctions()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters createSerdeParams(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void <init>(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.hive.llap.daemon.QueryFailedHandler,org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.DaemonId,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: org.codehaus.jettison.json.JSONObject createConfigJson(long,long,long,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory$KerberosUgiFactory: void <init>(java.lang.String,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server startProtocolServer(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.conf.Configuration,com.google.protobuf.BlockingService,java.lang.Class,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: org.apache.hadoop.hive.common.UgiFactory createFsUgiFactory(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.counters.QueryFragmentCounters: void <init>(org.apache.hadoop.conf.Configuration,org.apache.tez.common.counters.TezCounters)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: long getMaxTotalMemorySize(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter: org.apache.hadoop.hive.ql.io.orc.Writer createOrcWriter(org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector)>",
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void setFileMetadata(org.apache.hadoop.hive.llap.io.metadata.ConsumerFileMetadata)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: boolean isPermissiveManagementAcl(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: long determineXmxHeadroom(org.apache.hadoop.conf.Configuration,long,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter: void validateIncludes(org.apache.orc.OrcProto$Footer)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureOrcReader()>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: void <clinit>()>",
    "<org.apache.hadoop.hive.llap.cache.LowLevelLrfuCachePolicy: void <init>(int,long,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription,java.util.Map)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void logSecurityErrorRarely(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: org.apache.hadoop.hive.ql.plan.MapWork findMapWork(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void outputJson(java.io.PrintWriter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: org.apache.hadoop.hive.llap.daemon.impl.QueryFragmentInfo registerFragment(org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,int,int,java.lang.String,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo,org.apache.hadoop.hive.llap.LlapNodeId)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable: org.apache.tez.runtime.task.TaskRunner2Result callInternal()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: java.util.Set downloadPermanentFunctions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hive.llap.configuration.LlapDaemonConfiguration: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void <init>(org.apache.hadoop.conf.Configuration,int,long,boolean,boolean,long,java.lang.String[],int,int,int,int,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[],java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: org.apache.orc.TypeDescription getSchema()>",
    "<org.apache.hadoop.hive.llap.cache.SimpleAllocator: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.tez.runtime.api.impl.TezEvent extractInitialEvent(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.io.decode.GenericColumnVectorProducer$SerDeFileMetadata: void <init>(org.apache.hadoop.hive.serde2.Deserializer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void registerTask(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: int determineAllocSize(org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void initializeLogging(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: int run(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapIoImpl: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureMetadataReader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void <init>(org.apache.hadoop.conf.Configuration,int,int,boolean,java.lang.String[],java.util.concurrent.atomic.AtomicReference,java.util.concurrent.atomic.AtomicReference,long,org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorMetrics,org.apache.hadoop.hive.llap.daemon.impl.AMReporter,java.lang.ClassLoader,org.apache.hadoop.hive.llap.DaemonId,org.apache.hadoop.hive.common.UgiFactory,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices: void serviceInit(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: boolean determineRgsToRead(boolean[],int,java.util.ArrayList)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void copyConfig(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: int run(org.apache.hadoop.hive.llap.cli.LlapStatusOptionsProcessor$LlapStatusOptions,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void validateFileMetadata()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void taskKilled(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: java.util.List getRegisteredFragments()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.ql.io.sarg.SearchArgument,java.lang.String[],org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedFileRegion: void transferSuccessful()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void setupConf()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void main(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol getUmbilical()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$ExitCode populateAppStatusFromLlapRegistry(org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$AppStatusBuilder,long)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: void <init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.cache.MemoryManager,org.apache.hadoop.hive.llap.metrics.LlapDaemonCacheMetrics)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices$LlapPeerRegistryServlet: void doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void startReadSplitFromFile(org.apache.hadoop.mapred.FileSplit,boolean[],org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl$StripeData)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>"
  ],
  "2.3.2": [
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void decodeBatch(org.apache.hadoop.hive.ql.io.orc.encoded.Reader$OrcEncodedColumnBatch,org.apache.hadoop.hive.ql.io.orc.encoded.Consumer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkResponseProto submitWork(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo getTokenInfo(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl$TokenRequiresSigning getSigningConfig(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void populateConfWithLlapProperties(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.StaticPermanentFunctionChecker: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter create(org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,java.util.Map,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: void <init>(java.lang.Object,org.apache.hadoop.hive.ql.io.orc.Reader)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver$4: java.lang.Void call()>",
    "<org.apache.hadoop.hive.llap.cli.LlapSliderUtils: java.io.File startSetSliderLibDir()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void refreshClassloader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void init()>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: void <init>(org.apache.hadoop.hive.ql.plan.MapWork,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.FileSplit,java.util.List,java.lang.String,org.apache.hadoop.hive.llap.io.decode.ColumnVectorProducer,java.util.concurrent.ExecutorService,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server createServer(java.lang.Class,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,int,com.google.protobuf.BlockingService,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: void checkPermissions(java.lang.String,java.lang.String,java.lang.String,java.lang.Object)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle: org.jboss.netty.channel.ChannelFuture sendMapOutput(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.Channel,java.lang.String,java.lang.String,int,org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle$MapOutputInfo)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec extractVertexSpec(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: void setupUmbilicalUgi(java.lang.String,org.apache.hadoop.security.token.Token,java.lang.String,int)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenResponseProto getDelegationToken(com.google.protobuf.RpcController,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenRequestProto)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedChunkedFile: void close()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void startLocalizeAllFunctions()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters createSerdeParams(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void <init>(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.hive.llap.daemon.QueryFailedHandler,org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.DaemonId,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: org.codehaus.jettison.json.JSONObject createConfigJson(long,long,long,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory$KerberosUgiFactory: void <init>(java.lang.String,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server startProtocolServer(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.conf.Configuration,com.google.protobuf.BlockingService,java.lang.Class,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: org.apache.hadoop.hive.common.UgiFactory createFsUgiFactory(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.counters.QueryFragmentCounters: void <init>(org.apache.hadoop.conf.Configuration,org.apache.tez.common.counters.TezCounters)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: long getMaxTotalMemorySize(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter: org.apache.hadoop.hive.ql.io.orc.Writer createOrcWriter(org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector)>",
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void setFileMetadata(org.apache.hadoop.hive.llap.io.metadata.ConsumerFileMetadata)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: boolean isPermissiveManagementAcl(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: long determineXmxHeadroom(org.apache.hadoop.conf.Configuration,long,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter: void validateIncludes(org.apache.orc.OrcProto$Footer)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureOrcReader()>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: void <clinit>()>",
    "<org.apache.hadoop.hive.llap.cache.LowLevelLrfuCachePolicy: void <init>(int,long,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription,java.util.Map)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void logSecurityErrorRarely(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: org.apache.hadoop.hive.ql.plan.MapWork findMapWork(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void outputJson(java.io.PrintWriter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: org.apache.hadoop.hive.llap.daemon.impl.QueryFragmentInfo registerFragment(org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,int,int,java.lang.String,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo,org.apache.hadoop.hive.llap.LlapNodeId)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable: org.apache.tez.runtime.task.TaskRunner2Result callInternal()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: java.util.Set downloadPermanentFunctions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hive.llap.configuration.LlapDaemonConfiguration: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void <init>(org.apache.hadoop.conf.Configuration,int,long,boolean,boolean,long,java.lang.String[],int,int,int,int,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[],java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: org.apache.orc.TypeDescription getSchema()>",
    "<org.apache.hadoop.hive.llap.cache.SimpleAllocator: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.tez.runtime.api.impl.TezEvent extractInitialEvent(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.io.decode.GenericColumnVectorProducer$SerDeFileMetadata: void <init>(org.apache.hadoop.hive.serde2.Deserializer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void registerTask(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: int determineAllocSize(org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void initializeLogging(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: int run(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapIoImpl: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureMetadataReader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void <init>(org.apache.hadoop.conf.Configuration,int,int,boolean,java.lang.String[],java.util.concurrent.atomic.AtomicReference,java.util.concurrent.atomic.AtomicReference,long,org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorMetrics,org.apache.hadoop.hive.llap.daemon.impl.AMReporter,java.lang.ClassLoader,org.apache.hadoop.hive.llap.DaemonId,org.apache.hadoop.hive.common.UgiFactory,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices: void serviceInit(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: boolean determineRgsToRead(boolean[],int,java.util.ArrayList)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void copyConfig(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: int run(org.apache.hadoop.hive.llap.cli.LlapStatusOptionsProcessor$LlapStatusOptions,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void validateFileMetadata()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void taskKilled(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: java.util.List getRegisteredFragments()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.ql.io.sarg.SearchArgument,java.lang.String[],org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedFileRegion: void transferSuccessful()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void setupConf()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void main(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol getUmbilical()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$ExitCode populateAppStatusFromLlapRegistry(org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$AppStatusBuilder,long)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: void <init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.cache.MemoryManager,org.apache.hadoop.hive.llap.metrics.LlapDaemonCacheMetrics)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices$LlapPeerRegistryServlet: void doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void startReadSplitFromFile(org.apache.hadoop.mapred.FileSplit,boolean[],org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl$StripeData)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>"
  ],
  "2.3.7": [
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void decodeBatch(org.apache.hadoop.hive.ql.io.orc.encoded.Reader$OrcEncodedColumnBatch,org.apache.hadoop.hive.ql.io.orc.encoded.Consumer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkResponseProto submitWork(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo getTokenInfo(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl$TokenRequiresSigning getSigningConfig(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void populateConfWithLlapProperties(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.StaticPermanentFunctionChecker: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter create(org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,java.util.Map,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: void <init>(java.lang.Object,org.apache.hadoop.hive.ql.io.orc.Reader)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver$4: java.lang.Void call()>",
    "<org.apache.hadoop.hive.llap.cli.LlapSliderUtils: java.io.File startSetSliderLibDir()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void init()>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: void <init>(org.apache.hadoop.hive.ql.plan.MapWork,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.FileSplit,java.util.List,java.lang.String,org.apache.hadoop.hive.llap.io.decode.ColumnVectorProducer,java.util.concurrent.ExecutorService,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server createServer(java.lang.Class,java.net.InetSocketAddress,org.apache.hadoop.conf.Configuration,int,com.google.protobuf.BlockingService,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: void checkPermissions(java.lang.String,java.lang.String,java.lang.String,java.lang.Object)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle: org.jboss.netty.channel.ChannelFuture sendMapOutput(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.Channel,java.lang.String,java.lang.String,int,org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle$MapOutputInfo)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec extractVertexSpec(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: void setupUmbilicalUgi(java.lang.String,org.apache.hadoop.security.token.Token,java.lang.String,int)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenResponseProto getDelegationToken(com.google.protobuf.RpcController,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenRequestProto)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedChunkedFile: void close()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void startLocalizeAllFunctions()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: org.apache.hadoop.hive.serde2.lazy.LazySerDeParameters createSerdeParams(org.apache.hadoop.conf.Configuration,java.util.Properties)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void <init>(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.hive.llap.daemon.QueryFailedHandler,org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.DaemonId,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: org.codehaus.jettison.json.JSONObject createConfigJson(long,long,long,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory$KerberosUgiFactory: void <init>(java.lang.String,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.ipc.RPC$Server startProtocolServer(int,int,java.util.concurrent.atomic.AtomicReference,org.apache.hadoop.conf.Configuration,com.google.protobuf.BlockingService,java.lang.Class,org.apache.hadoop.hive.conf.HiveConf$ConfVars[])>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: org.apache.hadoop.hive.common.UgiFactory createFsUgiFactory(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.counters.QueryFragmentCounters: void <init>(org.apache.hadoop.conf.Configuration,org.apache.tez.common.counters.TezCounters)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: long getMaxTotalMemorySize(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$EncodingWriter: org.apache.hadoop.hive.ql.io.orc.Writer createOrcWriter(org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter,org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector)>",
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void setFileMetadata(org.apache.hadoop.hive.llap.io.metadata.ConsumerFileMetadata)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: boolean isPermissiveManagementAcl(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: long determineXmxHeadroom(org.apache.hadoop.conf.Configuration,long,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader$CacheWriter: void validateIncludes(org.apache.orc.OrcProto$Footer)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureOrcReader()>",
    "<org.apache.hadoop.hive.llap.security.LlapUgiFactoryFactory: void <clinit>()>",
    "<org.apache.hadoop.hive.llap.cache.LowLevelLrfuCachePolicy: void <init>(int,long,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter,org.apache.hadoop.mapred.InputFormat,org.apache.hadoop.hive.serde2.Deserializer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription,java.util.Map)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void logSecurityErrorRarely(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapRecordReader: org.apache.hadoop.hive.ql.plan.MapWork findMapWork(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void outputJson(java.io.PrintWriter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: org.apache.hadoop.hive.llap.daemon.impl.QueryFragmentInfo registerFragment(org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,java.lang.String,java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,int,int,java.lang.String,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo,org.apache.hadoop.hive.llap.LlapNodeId)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable: org.apache.tez.runtime.task.TaskRunner2Result callInternal()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: java.util.Set downloadPermanentFunctions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hive.llap.configuration.LlapDaemonConfiguration: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void <init>(org.apache.hadoop.conf.Configuration,int,long,boolean,boolean,long,java.lang.String[],int,int,int,int,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[],java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: org.apache.orc.TypeDescription getSchema()>",
    "<org.apache.hadoop.hive.llap.cache.SimpleAllocator: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: org.apache.tez.runtime.api.impl.TezEvent extractInitialEvent(org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SubmitWorkRequestProto,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.io.decode.GenericColumnVectorProducer$SerDeFileMetadata: void <init>(org.apache.hadoop.hive.serde2.Deserializer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void registerTask(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: int determineAllocSize(org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void initializeLogging(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: int run(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapIoImpl: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureMetadataReader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void <init>(org.apache.hadoop.conf.Configuration,int,int,boolean,java.lang.String[],java.util.concurrent.atomic.AtomicReference,java.util.concurrent.atomic.AtomicReference,long,org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorMetrics,org.apache.hadoop.hive.llap.daemon.impl.AMReporter,java.lang.ClassLoader,org.apache.hadoop.hive.llap.DaemonId,org.apache.hadoop.hive.common.UgiFactory,javax.net.SocketFactory)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices: void serviceInit(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: boolean determineRgsToRead(boolean[],int,java.util.ArrayList)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void copyConfig(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.fs.Path,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: int run(org.apache.hadoop.hive.llap.cli.LlapStatusOptionsProcessor$LlapStatusOptions,long)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void validateFileMetadata()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter: void taskKilled(java.lang.String,int,java.lang.String,org.apache.hadoop.security.token.Token,org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,org.apache.tez.dag.records.TezTaskAttemptID)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: java.util.List getRegisteredFragments()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.conf.Configuration,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.ql.io.sarg.SearchArgument,java.lang.String[],org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters,org.apache.orc.TypeDescription)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.FadvisedFileRegion: void transferSuccessful()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void setupConf()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void main(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol getUmbilical()>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$ExitCode populateAppStatusFromLlapRegistry(org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver$AppStatusBuilder,long)>",
    "<org.apache.hadoop.hive.llap.cache.BuddyAllocator: void <init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.hive.llap.cache.MemoryManager,org.apache.hadoop.hive.llap.metrics.LlapDaemonCacheMetrics)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices$LlapPeerRegistryServlet: void doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)>",
    "<org.apache.hadoop.hive.llap.io.encoded.VectorDeserializeOrcWriter: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector,java.util.List,boolean[],int)>",
    "<org.apache.hadoop.hive.llap.io.encoded.SerDeEncodedDataReader: void startReadSplitFromFile(org.apache.hadoop.mapred.FileSplit,boolean[],org.apache.hadoop.hive.llap.cache.SerDeLowLevelCacheImpl$StripeData)>"
  ],
  "2.1.0": [
    "<org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer: void decodeBatch(org.apache.hadoop.hive.ql.io.orc.encoded.Reader$OrcEncodedColumnBatch,org.apache.hadoop.hive.ql.io.orc.encoded.Consumer)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo getTokenInfo(java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat$LlapRecordReader: void <init>(org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.FileSplit,java.util.List,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureOrcReader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.StaticPermanentFunctionChecker: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.security.LlapSignerImpl: org.apache.hadoop.hive.llap.security.LlapSigner$SignedMessage serializeAndSign(org.apache.hadoop.hive.llap.security.LlapSigner$Signable)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void outputJson(java.io.PrintWriter)>",
    "<org.apache.hadoop.hive.llap.io.metadata.OrcFileMetadata: void <init>(java.lang.Object,org.apache.hadoop.hive.ql.io.orc.Reader)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable: org.apache.tez.runtime.task.TaskRunner2Result callInternal()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: java.util.Set downloadPermanentFunctions(org.apache.hadoop.conf.Configuration,org.apache.hadoop.fs.Path)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void refreshClassloader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void <init>(org.apache.hadoop.conf.Configuration,int,long,boolean,boolean,long,java.lang.String[],int,int,int,int,java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String[],java.lang.String)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: boolean isUdfAllowed(java.lang.Class)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.TaskRunnerCallable$1: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol run()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void init()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker: void checkPermissions(java.lang.String,java.lang.String,java.lang.String,java.lang.Object)>",
    "<org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle: org.jboss.netty.channel.ChannelFuture sendMapOutput(org.jboss.netty.channel.ChannelHandlerContext,org.jboss.netty.channel.Channel,java.lang.String,java.lang.String,int,org.apache.hadoop.hive.llap.shufflehandler.ShuffleHandler$Shuffle$MapOutputInfo)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void <init>(org.apache.hadoop.hive.llap.cache.LowLevelCache,org.apache.hadoop.hive.llap.cache.BufferUsageManager,org.apache.hadoop.hive.llap.io.metadata.OrcMetadataCache,org.apache.hadoop.conf.Configuration,org.apache.hadoop.mapred.FileSplit,java.util.List,org.apache.hadoop.hive.ql.io.sarg.SearchArgument,java.lang.String[],org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer,org.apache.hadoop.hive.llap.counters.QueryFragmentCounters)>",
    "<org.apache.hadoop.hive.llap.io.api.impl.LlapIoImpl: void <init>(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: void ensureMetadataReader()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryTracker: org.apache.hadoop.hive.llap.daemon.impl.QueryFragmentInfo registerFragment(org.apache.hadoop.hive.llap.daemon.impl.QueryIdentifier,java.lang.String,java.lang.String,int,java.lang.String,int,int,java.lang.String,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$SignableVertexSpec,org.apache.hadoop.security.token.Token,java.lang.String,org.apache.hadoop.hive.llap.daemon.impl.LlapTokenChecker$LlapTokenInfo)>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: boolean determineRgsToRead(boolean[],int,java.util.ArrayList)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices: void serviceInit(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.llap.cli.LlapStatusServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void <init>()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenResponseProto getDelegationToken(com.google.protobuf.RpcController,org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos$GetTokenRequestProto)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void startLocalizeAllFunctions()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapProtocolServerImpl: void serviceStart()>",
    "<org.apache.hadoop.hive.llap.cli.LlapServiceDriver: void run(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.QueryInfo: java.util.List getRegisteredFragments()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: java.lang.Void performDataRead()>",
    "<org.apache.hadoop.hive.llap.io.encoded.OrcEncodedDataReader: java.lang.Object determineFileId(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.FileSplit,boolean)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.LlapDaemon: void main(java.lang.String[])>",
    "<org.apache.hadoop.hive.llap.daemon.impl.AMReporter$AMNodeInfo: org.apache.hadoop.hive.llap.protocol.LlapTaskUmbilicalProtocol getUmbilical()>",
    "<org.apache.hadoop.hive.llap.daemon.impl.ContainerRunnerImpl: void <init>(org.apache.hadoop.conf.Configuration,int,int,boolean,java.lang.String[],java.util.concurrent.atomic.AtomicReference,java.util.concurrent.atomic.AtomicReference,long,org.apache.hadoop.hive.llap.metrics.LlapDaemonExecutorMetrics,org.apache.hadoop.hive.llap.daemon.impl.AMReporter,java.lang.ClassLoader,org.apache.hadoop.hive.llap.DaemonId)>",
    "<org.apache.hadoop.hive.llap.daemon.services.impl.LlapWebServices$LlapPeerRegistryServlet: void doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)>",
    "<org.apache.hadoop.hive.llap.daemon.impl.FunctionLocalizer: void <init>(org.apache.hadoop.conf.Configuration,java.lang.String)>"
  ]
}