{
  "3.1.3": [
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void addHBaseDelegationToken(org.apache.hadoop.conf.Configuration)>"
  ],
  "3.0.0": [
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void addHBaseDelegationToken(org.apache.hadoop.conf.Configuration)>"
  ],
  "3.1.2": [
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void addHBaseDelegationToken(org.apache.hadoop.conf.Configuration)>"
  ],
  "3.1.1": [
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void addHBaseDelegationToken(org.apache.hadoop.conf.Configuration)>"
  ],
  "3.1.0": [
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void addHBaseDelegationToken(org.apache.hadoop.conf.Configuration)>"
  ],
  "2.3.3": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.struct.AvroHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: long getTimestampVal(org.apache.hadoop.hive.ql.index.IndexSearchCondition)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.DefaultHBaseKeyFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createKeyObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: boolean serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,int,org.apache.hadoop.hive.serde2.ByteStream$Output)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: byte[] getConstantVal(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector,boolean)>",
    "<org.apache.hadoop.hive.hbase.struct.DefaultHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractStorageHandlerCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(org.apache.avro.Schema,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: java.lang.Class getInputFormatClass()>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.hbase.client.Scan createFilterScan(org.apache.hadoop.mapred.JobConf,int,int,boolean)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseInputFormatUtil: org.apache.hadoop.hbase.client.Scan getScan(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,java.lang.String)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: boolean isHBaseGenerateHFiles(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractResidualCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: org.apache.hadoop.io.Writable serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureTableJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc,java.util.Map)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ],
  "2.3.2": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.struct.AvroHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: long getTimestampVal(org.apache.hadoop.hive.ql.index.IndexSearchCondition)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.DefaultHBaseKeyFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createKeyObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: boolean serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,int,org.apache.hadoop.hive.serde2.ByteStream$Output)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: byte[] getConstantVal(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector,boolean)>",
    "<org.apache.hadoop.hive.hbase.struct.DefaultHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractStorageHandlerCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(org.apache.avro.Schema,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: java.lang.Class getInputFormatClass()>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.hbase.client.Scan createFilterScan(org.apache.hadoop.mapred.JobConf,int,int,boolean)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseInputFormatUtil: org.apache.hadoop.hbase.client.Scan getScan(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,java.lang.String)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: boolean isHBaseGenerateHFiles(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractResidualCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: org.apache.hadoop.io.Writable serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureTableJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc,java.util.Map)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ],
  "2.3.5": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.struct.AvroHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: long getTimestampVal(org.apache.hadoop.hive.ql.index.IndexSearchCondition)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.DefaultHBaseKeyFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createKeyObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: boolean serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,int,org.apache.hadoop.hive.serde2.ByteStream$Output)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: byte[] getConstantVal(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector,boolean)>",
    "<org.apache.hadoop.hive.hbase.struct.DefaultHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractStorageHandlerCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(org.apache.avro.Schema,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: java.lang.Class getInputFormatClass()>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.hbase.client.Scan createFilterScan(org.apache.hadoop.mapred.JobConf,int,int,boolean)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseInputFormatUtil: org.apache.hadoop.hbase.client.Scan getScan(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,java.lang.String)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: boolean isHBaseGenerateHFiles(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractResidualCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: org.apache.hadoop.io.Writable serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureTableJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc,java.util.Map)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ],
  "2.3.8": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>"
  ],
  "2.3.9": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>"
  ],
  "2.3.4": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.struct.AvroHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: long getTimestampVal(org.apache.hadoop.hive.ql.index.IndexSearchCondition)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.DefaultHBaseKeyFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createKeyObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: boolean serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,int,org.apache.hadoop.hive.serde2.ByteStream$Output)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: byte[] getConstantVal(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector,boolean)>",
    "<org.apache.hadoop.hive.hbase.struct.DefaultHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractStorageHandlerCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(org.apache.avro.Schema,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: java.lang.Class getInputFormatClass()>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.hbase.client.Scan createFilterScan(org.apache.hadoop.mapred.JobConf,int,int,boolean)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseInputFormatUtil: org.apache.hadoop.hbase.client.Scan getScan(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,java.lang.String)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: boolean isHBaseGenerateHFiles(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractResidualCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: org.apache.hadoop.io.Writable serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureTableJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc,java.util.Map)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ],
  "2.3.10": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>"
  ],
  "2.3.1": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.struct.AvroHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: long getTimestampVal(org.apache.hadoop.hive.ql.index.IndexSearchCondition)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.DefaultHBaseKeyFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createKeyObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: boolean serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,int,org.apache.hadoop.hive.serde2.ByteStream$Output)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: byte[] getConstantVal(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector,boolean)>",
    "<org.apache.hadoop.hive.hbase.struct.DefaultHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractStorageHandlerCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(org.apache.avro.Schema,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: java.lang.Class getInputFormatClass()>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.hbase.client.Scan createFilterScan(org.apache.hadoop.mapred.JobConf,int,int,boolean)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseInputFormatUtil: org.apache.hadoop.hbase.client.Scan getScan(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,java.lang.String)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: boolean isHBaseGenerateHFiles(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractResidualCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: org.apache.hadoop.io.Writable serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureTableJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc,java.util.Map)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ],
  "2.3.7": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.struct.AvroHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: long getTimestampVal(org.apache.hadoop.hive.ql.index.IndexSearchCondition)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.DefaultHBaseKeyFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createKeyObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: boolean serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,int,org.apache.hadoop.hive.serde2.ByteStream$Output)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: byte[] getConstantVal(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector,boolean)>",
    "<org.apache.hadoop.hive.hbase.struct.DefaultHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractStorageHandlerCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(org.apache.avro.Schema,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: java.lang.Class getInputFormatClass()>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.hbase.client.Scan createFilterScan(org.apache.hadoop.mapred.JobConf,int,int,boolean)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseInputFormatUtil: org.apache.hadoop.hbase.client.Scan getScan(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,java.lang.String)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: boolean isHBaseGenerateHFiles(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractResidualCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: org.apache.hadoop.io.Writable serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureTableJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc,java.util.Map)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ],
  "2.3.6": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.struct.AvroHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: long getTimestampVal(org.apache.hadoop.hive.ql.index.IndexSearchCondition)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.DefaultHBaseKeyFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createKeyObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: boolean serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,int,org.apache.hadoop.hive.serde2.ByteStream$Output)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: byte[] getConstantVal(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector,boolean)>",
    "<org.apache.hadoop.hive.hbase.struct.DefaultHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractStorageHandlerCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(org.apache.avro.Schema,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: java.lang.Class getInputFormatClass()>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.hbase.client.Scan createFilterScan(org.apache.hadoop.mapred.JobConf,int,int,boolean)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseInputFormatUtil: org.apache.hadoop.hbase.client.Scan getScan(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,java.lang.String)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: boolean isHBaseGenerateHFiles(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractResidualCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: org.apache.hadoop.io.Writable serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureTableJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc,java.util.Map)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ],
  "2.3.0": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.struct.AvroHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: long getTimestampVal(org.apache.hadoop.hive.ql.index.IndexSearchCondition)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.DefaultHBaseKeyFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createKeyObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: boolean serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,int,org.apache.hadoop.hive.serde2.ByteStream$Output)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: byte[] getConstantVal(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector,boolean)>",
    "<org.apache.hadoop.hive.hbase.struct.DefaultHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractStorageHandlerCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(org.apache.avro.Schema,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: java.lang.Class getInputFormatClass()>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.hbase.client.Scan createFilterScan(org.apache.hadoop.mapred.JobConf,int,int,boolean)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseInputFormatUtil: org.apache.hadoop.hbase.client.Scan getScan(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,java.lang.String)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: boolean isHBaseGenerateHFiles(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractResidualCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: org.apache.hadoop.io.Writable serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureTableJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc,java.util.Map)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ],
  "2.0.1": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>"
  ],
  "2.0.0": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.struct.AvroHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: long getTimestampVal(org.apache.hadoop.hive.ql.index.IndexSearchCondition)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.DefaultHBaseKeyFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createKeyObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: boolean serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,int,org.apache.hadoop.hive.serde2.ByteStream$Output)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: byte[] getConstantVal(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector,boolean)>",
    "<org.apache.hadoop.hive.hbase.struct.DefaultHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(org.apache.avro.Schema,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.hbase.client.Scan createFilterScan(org.apache.hadoop.mapred.JobConf,int,int,boolean)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseInputFormatUtil: org.apache.hadoop.hbase.client.Scan getScan(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: void setupKeyRange(org.apache.hadoop.hbase.client.Scan,java.util.List,boolean)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: org.apache.hadoop.io.Writable serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ],
  "2.1.0": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.struct.AvroHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: long getTimestampVal(org.apache.hadoop.hive.ql.index.IndexSearchCondition)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.DefaultHBaseKeyFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createKeyObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: boolean serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,int,org.apache.hadoop.hive.serde2.ByteStream$Output)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: byte[] getConstantVal(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector,boolean)>",
    "<org.apache.hadoop.hive.hbase.struct.DefaultHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractStorageHandlerCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(org.apache.avro.Schema,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.hbase.client.Scan createFilterScan(org.apache.hadoop.mapred.JobConf,int,int,boolean)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseInputFormatUtil: org.apache.hadoop.hbase.client.Scan getScan(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: void setupKeyRange(org.apache.hadoop.hbase.client.Scan,java.util.List,boolean)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractResidualCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: org.apache.hadoop.io.Writable serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ],
  "2.1.1": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.struct.AvroHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: long getTimestampVal(org.apache.hadoop.hive.ql.index.IndexSearchCondition)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.DefaultHBaseKeyFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createKeyObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: boolean serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,int,org.apache.hadoop.hive.serde2.ByteStream$Output)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: byte[] getConstantVal(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector,boolean)>",
    "<org.apache.hadoop.hive.hbase.struct.DefaultHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractStorageHandlerCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(org.apache.avro.Schema,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: java.lang.Class getInputFormatClass()>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.hbase.client.Scan createFilterScan(org.apache.hadoop.mapred.JobConf,int,int,boolean)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseInputFormatUtil: org.apache.hadoop.hbase.client.Scan getScan(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: void setupKeyRange(org.apache.hadoop.hbase.client.Scan,java.util.List,boolean)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: boolean isHBaseGenerateHFiles(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractResidualCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: org.apache.hadoop.io.Writable serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureTableJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc,java.util.Map)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ],
  "1.2.0": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.struct.AvroHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: long getTimestampVal(org.apache.hadoop.hive.ql.index.IndexSearchCondition)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.DefaultHBaseKeyFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createKeyObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: boolean serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,int,org.apache.hadoop.hive.serde2.ByteStream$Output)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: byte[] getConstantVal(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector,boolean)>",
    "<org.apache.hadoop.hive.hbase.struct.DefaultHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(org.apache.avro.Schema,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: java.lang.Class getInputFormatClass()>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseInputFormatUtil: org.apache.hadoop.hbase.client.Scan getScan(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,java.lang.String)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: boolean isHBaseGenerateHFiles(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: org.apache.hadoop.io.Writable serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureTableJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc,java.util.Map)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ],
  "1.2.1": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.struct.AvroHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: long getTimestampVal(org.apache.hadoop.hive.ql.index.IndexSearchCondition)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.DefaultHBaseKeyFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createKeyObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: boolean serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector,int,org.apache.hadoop.hive.serde2.ByteStream$Output)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: byte[] getConstantVal(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector,boolean)>",
    "<org.apache.hadoop.hive.hbase.struct.DefaultHBaseValueFactory: org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector createValueObjectInspector(org.apache.hadoop.hive.serde2.typeinfo.TypeInfo)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(org.apache.avro.Schema,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: java.lang.Class getInputFormatClass()>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: org.apache.hadoop.mapred.RecordWriter getRecordWriter(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf,java.lang.String,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseInputFormatUtil: org.apache.hadoop.hbase.client.Scan getScan(org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: void setupKeyRange(org.apache.hadoop.hbase.client.Scan,java.util.List,boolean)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: void <init>(org.apache.hadoop.conf.Configuration,java.util.Properties,java.lang.String)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: boolean isHBaseGenerateHFiles(org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseRowSerializer: org.apache.hadoop.io.Writable serialize(java.lang.Object,org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureTableJobProperties(org.apache.hadoop.hive.ql.plan.TableDesc,java.util.Map)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ]
}