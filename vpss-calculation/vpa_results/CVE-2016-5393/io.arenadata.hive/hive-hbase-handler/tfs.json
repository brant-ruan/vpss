{
  "2.3.9_arenadata3": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.hbase.client.Scan createFilterScan(org.apache.hadoop.mapred.JobConf,int,int,boolean)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractResidualCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractStorageHandlerCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ],
  "2.3.9_arenadata2": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.hbase.client.Scan createFilterScan(org.apache.hadoop.mapred.JobConf,int,int,boolean)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractResidualCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractStorageHandlerCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ],
  "2.3.9_arenadata1": [
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.hbase.client.Scan createFilterScan(org.apache.hadoop.mapred.JobConf,int,int,boolean)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeParameters: org.apache.avro.Schema getSchema(org.apache.hadoop.conf.Configuration,java.util.Properties,org.apache.hadoop.hive.hbase.ColumnMappings$ColumnMapping)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractResidualCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.RecordReader getRecordReader(org.apache.hadoop.mapred.InputSplit,org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.Reporter)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: void configureJobConf(org.apache.hadoop.hive.ql.plan.TableDesc,org.apache.hadoop.mapred.JobConf)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromClass(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HiveHBaseTableInputFormat: org.apache.hadoop.mapred.InputSplit[] getSplitsInternal(org.apache.hadoop.mapred.JobConf,int)>",
    "<org.apache.hadoop.hive.hbase.HBaseStorageHandler: org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc extractStorageHandlerCondition(org.apache.hadoop.hive.ql.index.IndexPredicateAnalyzer,java.util.List,org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: org.apache.hadoop.hive.ql.exec.FileSinkOperator$RecordWriter getHiveRecordWriter(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.fs.Path,java.lang.Class,boolean,java.util.Properties,org.apache.hadoop.util.Progressable)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: void generateAvroStructFromSchema(java.lang.String,java.lang.StringBuilder)>",
    "<org.apache.hadoop.hive.hbase.HBaseSerDeHelper: org.apache.avro.Schema getSchemaFromFS(java.lang.String,org.apache.hadoop.conf.Configuration)>",
    "<org.apache.hadoop.hive.hbase.HiveHFileOutputFormat: void checkOutputSpecs(org.apache.hadoop.fs.FileSystem,org.apache.hadoop.mapred.JobConf)>"
  ]
}